
@article{ABC_Handbook,
  title = {Handbook of {{Approximate Bayesian Computation}}. {{Edited}} by {{Scott A}}. {{Sisson}}, {{Yanan Fan}}, {{Mark A}}. {{Beaumont}} (2019). {{London}}, {{UK}}: {{Chapman}} \& {{Hall}}/{{CRC Press}}. 662 Pages, {{ISBN}}: 978-1-4398-8150-7.},
  shorttitle = {Handbook of {{Approximate Bayesian Computation}}. {{Edited}} by {{Scott A}}. {{Sisson}}, {{Yanan Fan}}, {{Mark A}}. {{Beaumont}} (2019). {{London}}, {{UK}}},
  author = {Götte, Heiko},
  date = {2019},
  journaltitle = {Biometrical Journal},
  volume = {61},
  pages = {1601--1602},
  issn = {1521-4036},
  doi = {10.1002/bimj.201900141},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201900141},
  urldate = {2019-11-08},
  file = {/home/marcos/Zotero/storage/H4IKHKCP/bimj.html},
  langid = {english},
  number = {6}
}

@article{andrew_philosophy_nodate,
  title = {Philosophy and the Practice of {{Bayesian}} Statistics},
  author = {Andrew, Gelman and Rohilla, Shalizi Cosma},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  volume = {66},
  pages = {8--38},
  doi = {10.1111/j.2044-8317.2011.02037.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2011.02037.x},
  abstract = {A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico‐deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science. Clarity about these matters should benefit not just philosophy of science, but also statistical practice. At best, the inductivist view has encouraged researchers to fit and compare models without checking them; at worst, theorists have actively discouraged practitioners from performing model checking because it does not fit into their framework.},
  number = {1}
}

@article{antino_rethinking_2018,
  title = {Rethinking the {{Exploration}} of {{Dichotomous Data}}: {{Mokken Scale Analysis Versus Factorial Analysis}}},
  author = {Antino, Mirko and Alvarado, Jesús M. and Asún, Rodrigo A. and Bliese, Paul},
  date = {2018-04},
  journaltitle = {Sociological Methods \& Research},
  pages = {0049124118769090--},
  issn = {0049-1241},
  doi = {10.1177/0049124118769090},
  url = {https://doi.org/10.1177/0049124118769090},
  abstract = {The need to determine the correct dimensionality of theoretical constructs and generate valid measurement instruments when underlying items are categorical has generated a significant volume of research in the social sciences. This article presents two studies contrasting different categorical exploratory techniques. The first study compares Mokken scale analysis (MSA) and two-factor-based exploratory techniques for noncontinuous variables: item factor analysis and Normal Ogive Harmonic Analysis Robust Method (NOHARM). Comparisons are conducted across techniques and in reference to the common principal component analysis model using simulated data under conditions of two-dimensionality with different degrees of correlation (r = .0 to .6). The second study shows the theoretical and practical results of using MSA and NOHARM (the factorial technique which functioned best in the first study) on two nonsimulated data sets. The nonsimulated data are particularly interesting because MSA was used to solve a theoretical debate. Based on the results from both studies, we show that the ability of NOHARM to detect dimensionality and scalability is similar to MSA when the data comprise two uncorrelated latent dimensions; however, NOHARM is preferable when data are drawn from instruments containing latent dimensions weakly or moderately correlated. This article discusses the theoretical and practical implications of these findings.}
}

@article{archer_knights_2005,
  title = {Knight’s Move Thinking? {{Mild}} Cognitive Impairment in a Chess Player},
  author = {Archer, H. A. and Schott, J. M. and Barnes, J. and Fox, N. C. and Holton, J. L. and Revesz, T. and Cipolotti, L. and Rossor, M. N.},
  date = {2005},
  journaltitle = {Neurocase},
  volume = {11},
  pages = {26--31},
  doi = {10.1080/13554790490896875},
  url = {https://doi.org/10.1080/13554790490896875},
  eprint = {15804921},
  eprinttype = {pmid},
  number = {1}
}

@article{ark_mokken_2007,
  title = {Mokken {{Scale Analysis}} in {{R}}},
  author = {van der Ark, L. Andries},
  date = {2007},
  journaltitle = {Journal of Statistical Software, Articles},
  volume = {20},
  pages = {1--19},
  issn = {1548-7660},
  doi = {10.18637/jss.v020.i11},
  url = {https://www.jstatsoft.org/v020/i11},
  abstract = {Mokken scale analysis (MSA) is a scaling procedure for both dichotomous and polytomous items. It consists of an item selection algorithm to partition a set of items into Mokken scales and several methods to check the assumptions of two nonparametric item response theory models: the monotone homogeneity model and the double monotonicity model. First, we present an R package mokken for MSA and explain the procedures. Second, we show how to perform MSA in R using test data obtained with the Adjective Checklist.},
  number = {11}
}

@book{auguie_gridextra_2017,
  title = {{{gridExtra}}: {{Miscellaneous Functions}} for "{{Grid}}" {{Graphics}}},
  author = {Auguie, Baptiste},
  date = {2017},
  url = {https://CRAN.R-project.org/package=gridExtra}
}

@book{aust_citr_2017,
  title = {Citr: '{{RStudio}}' {{Add}}-in to {{Insert Markdown Citations}}},
  author = {Aust, Frederik},
  date = {2017},
  url = {https://github.com/crsh/citr}
}

@book{aust_papaja_2017,
  title = {Papaja: {{Create APA}} Manuscripts with {{R Markdown}}},
  author = {Aust, Frederik and Barth, Marius},
  date = {2017},
  url = {https://github.com/crsh/papaja}
}

@article{baghaei_linear_2015,
  title = {Linear {{Logistic Test Modeling}} with {{R}}.},
  author = {Baghaei, Purya and Kubinger, Klaus D},
  date = {2015},
  journaltitle = {Practical assessment, research \& evaluation},
  volume = {20}
}

@article{banks_editorial_2016,
  title = {Editorial: {{Evidence}} on {{Questionable Research Practices}}: {{The Good}}, the {{Bad}}, and the {{Ugly}}},
  author = {Banks, George C. and Rogelberg, Steven G. and Woznyj, Haley M. and Landis, Ronald S. and Rupp, Deborah E.},
  date = {2016-09},
  journaltitle = {Journal of Business and Psychology},
  volume = {31},
  pages = {323--338},
  issn = {1573-353X},
  doi = {10.1007/s10869-016-9456-7},
  url = {https://doi.org/10.1007/s10869-016-9456-7},
  abstract = {Questionable research or reporting practices (QRPs) contribute to a growing concern regarding the credibility of research in the organizational sciences and related fields. Such practices include design, analytic, or reporting practices that may introduce biased evidence, which can have harmful implications for evidence-based practice, theory development, and perceptions of the rigor of science.},
  number = {3}
}

@article{barberia_short_2018,
  title = {A Short Educational Intervention Diminishes Causal Illusions and Specific Paranormal Beliefs in Undergraduates},
  author = {Barberia, Itxaso and Tubau, Elisabet and Matute, Helena and Rodríguez-Ferreiro, Javier},
  date = {2018-01},
  journaltitle = {PLOS ONE},
  volume = {13},
  pages = {1--14},
  doi = {10.1371/journal.pone.0191907},
  url = {https://doi.org/10.1371/journal.pone.0191907},
  abstract = {Cognitive biases such as causal illusions have been related to paranormal and pseudoscientific beliefs and, thus, pose a real threat to the development of adequate critical thinking abilities. We aimed to reduce causal illusions in undergraduates by means of an educational intervention combining training-in-bias and training-in-rules techniques. First, participants directly experienced situations that tend to induce the Barnum effect and the confirmation bias. Thereafter, these effects were explained and examples of their influence over everyday life were provided. Compared to a control group, participants who received the intervention showed diminished causal illusions in a contingency learning task and a decrease in the precognition dimension of a paranormal belief scale. Overall, results suggest that evidence-based educational interventions like the one presented here could be used to significantly improve critical thinking skills in our students.},
  number = {1}
}

@article{barrett_2003,
  title = {Beyond Psychometrics: {{Measurement}}, Non-Quantitative Structure, and Applied Numerics},
  shorttitle = {Beyond Psychometrics},
  author = {Barrett, Paul},
  date = {2003},
  journaltitle = {Journal of Managerial Psychology},
  volume = {18},
  pages = {421--439},
  issn = {1758-7778(Electronic),0268-3946(Print)},
  doi = {10.1108/02683940310484026},
  abstract = {A statement from Michell (Michell, J., "Normal science, pathological science, and psychometrics", Theory and Psychology, Vol. 10 No. 5, 2000, pp. 639-67), "psychometrics is a pathology of science", is contrasted with conventional definitions provided by leading texts. The key to understanding why Michell has made such a statement is bound up in the definition of measurement that characterises quantification of variables within the natural sciences. By describing the key features of quantitative measurement, and contrasting these with current psychometric practice, it is argued that Michell is correct in his assertion. Three avenues of investigation would seem to follow from this position, each of which, it is suggested, will gradually replace current psychometric test theory, principles, and properties. The first attempts to construct variables that can be demonstrated empirically to possess a quantitative structure. The second proceeds on the basis of using qualitative (non-quantitatively structured) variable structures and procedures... (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  file = {/home/marcos/Zotero/storage/V499WK8J/2003-99756-004.html},
  keywords = {Item Response Theory,Measurement,Psychometrics,Qualitative Methods,Quantitative Methods},
  number = {5}
}

@book{barrett_ggdag_2018,
  title = {Ggdag: {{Analyze}} and {{Create Elegant Directed Acyclic Graphs}}},
  author = {Barrett, Malcolm},
  date = {2018},
  url = {https://github.com/malcolmbarrett/ggdag}
}

@book{bingham_aptitudes_1937,
  title = {Aptitudes and Aptitude Testing.},
  author = {Bingham, W. V.},
  date = {1937},
  publisher = {{Harpers}},
  location = {{Oxford, England}},
  abstract = {Part I deals with aptitudes and guidance, with a treatment of basic concepts and a theory of aptitude. The pertinent use of interest inventories in counselling, the relationship between intelligence and vocation and between interests and attitudes, and the use of achievement tests as indicators of aptitudes are discussed. Part II considers the world of work and the aptitudes required for success in manual occupations, skilled trades, clerical occupations and the professions. In Part III the selection, administration and interpretation of tests are dealt with. An appendix lists and explains representative tests of visual and auditory acuity, of manual, mechanical, clerical and scientific aptitudes, of intelligence, and of esthetic judgments. An inventory of the Cooperative Test Service achievement tests, a reproduction of the Minnesota Occupational Rating Scales and of certain occupational interest blanks, and a directory of publishers and distributors completes the manual. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  pagetotal = {viii, 390–viii, 390}
}

@article{blum_automatic_2018,
  title = {Automatic {{Generation}} of {{Figural Analogies With}} the {{IMak Package}}},
  author = {Blum, Diego and Holling, Heinz},
  date = {2018},
  journaltitle = {Frontiers in Psychology},
  volume = {9},
  pages = {1286},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.01286},
  url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.01286},
  abstract = {Automatic Item Generation (AIG) techniques are offering innovative ways to produce test items as they overcome many disadvantages involving standard item writing, such as time-consuming work and resource-intensive demands. Although this field is relatively new, it is progressing at a high speed, and several contributions have been accomplished. Nevertheless, a scarce amount of AIG software evidencing favorable psychometric properties of the generated items has been made accessible to the broad scientific community. This research had two goals: first, to present an empirical study of items produced with the aid of the Item Maker (IMak) package available online and, second, to present IMak itself for the automatic generation of figural analogies. We were particularly interested in assessing whether automatically created figural analogy rules could predict item psychometric difficulty. A total of 23 items were generated and administered to 307 participants, 49.51\% from Germany. The mean age was 28.61 (SD = 10.19) and 57.65\% of the participants were female. Results reveal adequate psychometric properties including convergent validity, that most of the manipulated rules contribute to item difficulty, and that rule-based difficulty prediction is possible to some extent. In other words, psychometric quality of the generated items is supported, which reveals the utility of the IMak package in assessment settings. Finally, the package is presented and its functions for figural analogy item generation are further described.}
}

@article{blum_task_2016,
  title = {Task Difficulty Prediction of Figural Analogies},
  author = {Blum, Diego and Holling, Heinz and Galibert, Maria Silvia and Forthmann, Boris},
  date = {2016},
  journaltitle = {Intelligence},
  volume = {56},
  pages = {72--81},
  issn = {0160-2896},
  doi = {https://doi.org/10.1016/j.intell.2016.03.001},
  url = {http://www.sciencedirect.com/science/article/pii/S0160289616300927},
  abstract = {The purpose of this psychometric study is to explain performance on cognitive tasks pertaining Analogical Reasoning that were taken into consideration during the construction of a Test of Figural Analogies. For this purpose, a general Linear Logistic Test Model (LLTM) was mainly used for data analysis. A 30-itemed Test of Figural Analogies was administered to a sample of 422 students from Argentina, and eight of these items were administered along with a Matrices Test to 84 participants mostly from Germany. Women represented 77\% and 76\% of each respective sample. Indicators of validity and reliability show acceptable results. Item difficulties can be predicted by a set of nine Cognitive Operations to a satisfactory extent, as the Pearson correlation between the Rasch model and the LLTM item difficulty parameters r=.89, the mean prediction error is slightly different between the two models, and there is an overall effect of the number of combined rules on item difficulty (F(3,23)=15.16, p{$<$}.001) with an effect size η2=.66 (large effect). Results suggest that almost all rotation rules are highly influential on item difficulty.},
  keywords = {Figural analogies,Item difficulty,LLTM,Rasch model,Rules}
}

@article{box_cox_1964,
  title = {An {{Analysis}} of {{Transformations}}},
  author = {Box, G. E. P. and Cox, D. R.},
  date = {1964},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {26},
  pages = {211--243},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1964.tb00553.x},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1964.tb00553.x},
  urldate = {2020-02-10},
  abstract = {In the analysis of data it is often assumed that observations y1, y2, …, yn are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.},
  file = {/home/marcos/Zotero/storage/3GALTRD5/j.2517-6161.1964.tb00553.html},
  langid = {english},
  number = {2}
}

@book{brown_confirmatory_2006,
  title = {Confirmatory Factor Analysis for Applied Research.},
  author = {Brown, Timothy A.},
  date = {2006},
  publisher = {{Guilford Press}},
  location = {{New York, NY, US}},
  abstract = {Emphasizing practical and theoretical aspects of confirmatory factor analysis (CFA) rather than mathematics or formulas, Timothy A. Brown uses rich examples derived from the psychology, management, and sociology literatures to provide in-depth treatment of the concepts, procedures, pitfalls, and extensions of CFA methodology. Chock full of useful advice and tables that outline the procedures, the text shows readers how to conduct exploratory factor analysis (EFA) and understand similarities to and differences from CFA; formulate, program, and interpret CFA models using popular latent variable software packages such as LISREL, Mplus, Amos, EQS, and SAS/CALIS; and report results from a CFA study. Also covered are extensions of CFA to traditional item response theory (IRT) analysis, methods for determining necessary sample sizes, and new CFA modeling possibilities, including multilevel factor models and factor mixture models. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Applied Psychology,*Computer Software,*Experimentation,Factor Analysis},
  pagetotal = {xiii, 475–xiii, 475}
}

@book{campbell_1920,
  title = {Physics: {{The Elements}}},
  shorttitle = {Physics},
  author = {Campbell, Norman Robert},
  date = {1920},
  publisher = {{Cambridge University Press}},
  abstract = {Norman Robert Campbell (1880-1949) was an English physicist and philosopher who made a significant contribution to the philosophy of science. In this book, which was first published in 1920, Campbell presents a detailed critical analysis of various areas of physics. Aimed at the advanced reader, with a 'familiarity with all the facts and theories of physics, ancient and modern', the text is divided into two main parts: the first part deals with 'The Propositions of Science' and the second discusses aspects of 'Measurement'. An appendix and detailed index are also included. This book will be of value to anyone with an interest in the development of physics and the history of science.},
  isbn = {978-1-107-63068-0},
  keywords = {Science / Physics / General},
  langid = {english},
  pagetotal = {578}
}

@book{chang_shiny_2017,
  title = {Shiny: {{Web Application Framework}} for {{R}}},
  author = {Chang, Winston and Cheng, Joe and Allaire, J. J. and Xie, Yihui and McPherson, Jonathan},
  date = {2017},
  url = {https://CRAN.R-project.org/package=shiny}
}

@article{cliff_abstract_1992,
  title = {Abstract {{Measurement Theory}} and the {{Revolution That Never Happened}}},
  author = {Cliff, Norman},
  date = {1992},
  journaltitle = {Psychological Science},
  volume = {3},
  pages = {186--190},
  issn = {09567976, 14679280},
  eprint = {40062782},
  eprinttype = {jstor},
  number = {3}
}

@article{colquhoun_2014,
  title = {An Investigation of the False Discovery Rate and the Misinterpretation of P-Values},
  author = {Colquhoun, David},
  date = {2014},
  journaltitle = {Royal Society Open Science},
  shortjournal = {Royal Society Open Science},
  volume = {1},
  pages = {140216},
  doi = {10.1098/rsos.140216},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsos.140216},
  urldate = {2020-03-03},
  abstract = {If you use p=0.05 to suggest that you have made a discovery, you will be wrong at least 30\% of the time. If, as is often the case, experiments are underpowered, you will be wrong most of the time. This conclusion is demonstrated from several points of view. First, tree diagrams which show the close analogy with the screening test problem. Similar conclusions are drawn by repeated simulations of t-tests. These mimic what is done in real life, which makes the results more persuasive. The simulation method is used also to evaluate the extent to which effect sizes are over-estimated, especially in underpowered experiments. A script is supplied to allow the reader to do simulations themselves, with numbers appropriate for their own work. It is concluded that if you wish to keep your false discovery rate below 5\%, you need to use a three-sigma rule, or to insist on p≤0.001. And never use the word ‘significant’.},
  file = {/home/marcos/Zotero/storage/7W54QTXD/Colquhoun - An investigation of the false discovery rate and t.pdf;/home/marcos/Zotero/storage/VS5DXPM8/rsos.html},
  number = {3}
}

@article{colquhoun_2017,
  title = {The Reproducibility of Research and the Misinterpretation of P-Values},
  author = {Colquhoun, David},
  date = {2017},
  journaltitle = {Royal Society Open Science},
  shortjournal = {Royal Society Open Science},
  volume = {4},
  pages = {171085},
  doi = {10.1098/rsos.171085},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.171085},
  urldate = {2020-03-04},
  abstract = {We wish to answer this question: If you observe a ‘significant’ p-value after doing a single unbiased experiment, what is the probability that your result is a false positive? The weak evidence provided by p-values between 0.01 and 0.05 is explored by exact calculations of false positive risks. When you observe p\,=\,0.05, the odds in favour of there being a real effect (given by the likelihood ratio) are about 3\,:\,1. This is far weaker evidence than the odds of 19 to 1 that might, wrongly, be inferred from the p-value. And if you want to limit the false positive risk to 5\%, you would have to assume that you were 87\% sure that there was a real effect before the experiment was done. If you observe p\,=\,0.001 in a well-powered experiment, it gives a likelihood ratio of almost 100\,:\,1 odds on there being a real effect. That would usually be regarded as conclusive. But the false positive risk would still be 8\% if the prior probability of a real effect were only 0.1. And, in this case, if you wanted to achieve a false positive risk of 5\% you would need to observe p\,=\,0.00045. It is recommended that the terms ‘significant’ and ‘non-significant’ should never be used. Rather, p-values should be supplemented by specifying the prior probability that would be needed to produce a specified (e.g. 5\%) false positive risk. It may also be helpful to specify the minimum false positive risk associated with the observed p-value. Despite decades of warnings, many areas of science still insist on labelling a result of p\,{$<$}\,0.05 as ‘statistically significant’. This practice must contribute to the lack of reproducibility in some areas of science. This is before you get to the many other well-known problems, like multiple comparisons, lack of randomization and p-hacking. Precise inductive inference is impossible and replication is the only way to be sure. Science is endangered by statistical misunderstanding, and by senior people who impose perverse incentives on scientists.},
  file = {/home/marcos/Zotero/storage/7N57BPWK/Colquhoun - The reproducibility of research and the misinterpr.pdf;/home/marcos/Zotero/storage/VBVTDACZ/rsos.html},
  number = {12}
}

@article{cook_1982,
  title = {Cook, {{R}}. {{D}}., {{S}}. {{Weisberg}}: {{Residuals}} and Influence in Regression. {{Chapman}} and {{Hall}}, {{New York}} — {{London}} 1982},
  shorttitle = {Cook, {{R}}. {{D}}., {{S}}. {{Weisberg}}},
  author = {Läuter, H.},
  date = {1982},
  journaltitle = {Biometrical Journal},
  volume = {27},
  pages = {229},
  issn = {1521-4036},
  doi = {10.1002/bimj.4710270110},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.4710270110},
  urldate = {2020-02-17},
  file = {/home/marcos/Zotero/storage/8VD924IG/bimj.html},
  langid = {english},
  number = {1}
}

@article{cureton_validity_1950,
  title = {Validity, {{Reliability}}, and {{Baloney}}},
  author = {Cureton, Edward E.},
  date = {1950-04},
  journaltitle = {Educational and Psychological Measurement},
  volume = {10},
  pages = {94--96},
  issn = {0013-1644},
  doi = {10.1177/001316445001000107},
  url = {https://doi.org/10.1177/001316445001000107},
  number = {1}
}

@article{domingue_2014,
  title = {Evaluating the {{Equal}}-{{Interval Hypothesis}} with {{Test Score Scales}}},
  author = {Domingue, Ben},
  date = {2014-01-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {79},
  pages = {1--19},
  issn = {1860-0980},
  doi = {10.1007/s11336-013-9342-4},
  url = {https://doi.org/10.1007/s11336-013-9342-4},
  urldate = {2019-11-10},
  abstract = {The axioms of additive conjoint measurement provide a means of testing the hypothesis that testing data can be placed onto a scale with equal-interval properties. However, the axioms are difficult to verify given that item responses may be subject to measurement error. A Bayesian method exists for imposing order restrictions from additive conjoint measurement while estimating the probability of a correct response. In this study an improved version of that methodology is evaluated via simulation. The approach is then applied to data from a reading assessment intentionally designed to support an equal-interval scaling.},
  file = {/home/marcos/Zotero/storage/IB7AJH6X/Domingue - 2014 - Evaluating the Equal-Interval Hypothesis with Test.pdf},
  keywords = {conjoint measurement,interval scale,Rasch model},
  langid = {english},
  number = {1}
}

@article{ellenberg_1973,
  title = {The {{Joint Distribution}} of the {{Standardized Least Squares Residuals}} from a {{General Linear Regression}}},
  author = {Ellenberg, Jonas H.},
  date = {1973-12-01},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {68},
  pages = {941--943},
  issn = {0162-1459},
  doi = {10.1080/01621459.1973.10481450},
  url = {https://www.tandfonline.com/doi/10.1080/01621459.1973.10481450},
  urldate = {2020-02-18},
  abstract = {In this article the p-variate joint distribution is derived for a subset of p of the n standardized least squares residuals from a general linear regression. The resulting distribution is a standardized version of the Inverted-Student Function [8, p. 259]. An application of this result to the problem of detection of outliers is discussed.},
  file = {/home/marcos/Zotero/storage/IBRZILYZ/01621459.1973.html},
  number = {344}
}

@book{fechner_elemente_1860,
  title = {Elemente Der {{Psychophysik}}},
  author = {Fechner, Gustav Theodor},
  date = {1860},
  volume = {2},
  publisher = {{Breitkopf u. Härtel}}
}

@article{finch_performance_2007,
  title = {Performance of {{DIMTEST}}- and {{NOHARM}}-{{Based Statistics}} for {{Testing Unidimensionality}}},
  author = {Finch, Holmes and Habing, Brian},
  date = {2007-07},
  journaltitle = {Applied Psychological Measurement},
  volume = {31},
  pages = {292--307},
  issn = {0146-6216},
  doi = {10.1177/0146621606294490},
  url = {https://doi.org/10.1177/0146621606294490},
  abstract = {This Monte Carlo study compares the ability of the parametric bootstrap version of DIMTEST with three goodness-of-fit tests calculated from a fitted NOHARM model to detect violations of the assumption of unidimensionality in testing data. The effectiveness of the procedures was evaluated for different numbers of items, numbers of examinees, correlations between underlying ability dimensions, skewness of underlying ability distributions, and the presence or absence of a guessing parameter. In the absence of guessing, DIMTEST and the NOHARM-based statistics had similar power, with the ?2 statistic having a very low Type I error rate. In the presence of guessing, however, two of the NOHARM-based statistics had unacceptably high Type I error rates, while the third performed similarly to DIMTEST. Given this inflated error rate, the study compares the empirical powers after adjusting for the discrepancy in Type I error rates.},
  number = {4}
}

@book{FoM_1971,
  title = {Additive and {{Polynomial Representations}}},
  author = {Krantz, David H. and Suppes, Patrick and Luce, R. Duncan and Tversky, Amos},
  date = {1971},
  publisher = {{Courier Corporation}},
  abstract = {All of the sciences — physical, biological, and social — have a need for quantitative measurement. This influential series, Foundations of Measurement, established the formal foundations for measurement, justifying the assignment of numbers to objects in terms of their structural correspondence. Volume I introduces the distinct mathematical results that serve to formulate numerical representations of qualitative structures. Volume II extends the subject in the direction of geometrical, threshold, and probabilistic representations, and Volume III examines representation as expressed in axiomatization and invariance.},
  eprint = {aZ3bmPjCc9QC},
  eprinttype = {googlebooks},
  isbn = {978-0-486-45314-9},
  keywords = {Mathematics / General,Mathematics / Measurement},
  langid = {english},
  pagetotal = {626}
}

@book{FoM_1989,
  title = {Foundations of {{Measurement}}: {{Geometrical}}, Threshold, and Probabilistic Representations},
  shorttitle = {Foundations of {{Measurement}}},
  author = {Suppes, Patrick and Krantz, David H. and Tversky, Amos and Luce, Robert Duncan},
  date = {1989},
  publisher = {{Courier Corporation}},
  abstract = {The return of a classic series in the field of quantitative measurement. All of the sciences - physical, biological, and social - have a need for quantitative measurement. This influential but hard-to-find series established the formal foundations for measurement, justifying the assignment of numbers to objects in terms of their structural correspondence. Volume II extends the subject in the direction of geometrical, threshold, and probabilistic representations, and Volume III examines representation as expressed in axiomatization and invariance.},
  isbn = {978-0-486-45315-6},
  keywords = {Mathematics / General,Mathematics / Measurement},
  langid = {english},
  pagetotal = {514}
}

@book{FoM_1990,
  title = {Foundations of {{Measurement}}: {{Representation}}, Axiomatization, and Invariance},
  shorttitle = {Foundations of {{Measurement}}},
  author = {Luce, Robert Duncan and Suppes, Patrick and Krantz, David H. and Tversky, Amos},
  date = {1990},
  publisher = {{Courier Corporation}},
  abstract = {This classic series in the field of quantitative measurement established the formal foundations for measurement, justifying the assignment of numbers to objects in terms of their structural correspondence. Volume III examines representation as expressed in axiomatization and invariance.},
  eprint = {D29i15JCKo8C},
  eprinttype = {googlebooks},
  isbn = {978-0-486-45316-3},
  keywords = {Mathematics / General,Mathematics / Measurement},
  langid = {english},
  pagetotal = {386}
}

@book{gabry_bayesplot_2017,
  title = {Bayesplot: {{Plotting}} for {{Bayesian Models}}},
  author = {Gabry, Jonah and Mahr, Tristan},
  date = {2017},
  url = {https://CRAN.R-project.org/package=bayesplot}
}

@book{garrett_statistics_1937,
  title = {Statistics in Psychology and Education, 2nd Ed.},
  author = {Garrett, H. E.},
  date = {1937},
  publisher = {{Longmans, Green}},
  location = {{Oxford, England}},
  abstract = {This edition is 176 pages longer than the former one. "The treatment of percentiles, of comparable scores, of reliability and validity of tests has been expanded; and new material has been added to the chapters dealing with the normal probability curve, sampling and reliability of measures, and correlational methods. Breaking down the chapters of the old book into smaller and more comprehensible units should improve the teachability of the new book." The various chapters are concluded with problems for the student (plus answers), and at the close of the volume numerous reference tables are to be found. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  pagetotal = {493–493}
}

@article{Green_1986,
  title = {Fundamental {{Measurement}}},
  author = {Green, Kathy E.},
  date = {1986-04-01},
  journaltitle = {The Journal of Experimental Education},
  volume = {54},
  pages = {141--147},
  issn = {0022-0973},
  doi = {10.1080/00220973.1986.10806412},
  url = {https://doi.org/10.1080/00220973.1986.10806412},
  urldate = {2019-11-13},
  abstract = {Additive conjoint measurement is one of a number of theories allowing interval measurement of psychological and social attributes. If certain axioms are satisfied, the theory proves the existence of certain representations of the data. While clearly of great value theoretically, additive conjoint methods have rarely been used in education (with the exception of Rasch models). The measurement theory is algebraic and deals with deterministic (perfectly reliable) data. The lack of a commonly agreed upon method for determining model fit in the presence of error has limited its use. This paper reviews methods for assessing fit to an additive conjoint model, outlines another method for assessing fit, and reports an application of the method to a problem in educational testing. Multiple-choice test items were systematically varied along two dimensions (language difficulty and semantic similarity of response options) and the effects on item difficulty assessed. Some theoretical and practical implications of the study are discussed.},
  file = {/home/marcos/Zotero/storage/ZFCLX2IT/00220973.1986.html},
  number = {3}
}

@article{greenland_statistical_2016,
  title = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power: A Guide to Misinterpretations},
  author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
  date = {2016-04},
  journaltitle = {European Journal of Epidemiology},
  volume = {31},
  pages = {337--350},
  issn = {1573-7284},
  doi = {10.1007/s10654-016-0149-3},
  url = {https://doi.org/10.1007/s10654-016-0149-3},
  abstract = {Misinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so—and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.},
  number = {4}
}

@book{gronau_bridgesampling_2017,
  title = {Bridgesampling: {{Bridge Sampling}} for {{Marginal Likelihoods}} and {{Bayes Factors}}},
  author = {Gronau, Quentin F. and Singmann, Henrik},
  date = {2017},
  url = {https://CRAN.R-project.org/package=bridgesampling}
}

@article{guilford_new_1946,
  title = {New {{Standards For Test Evaluation}}},
  author = {Guilford, J. P.},
  date = {1946-12},
  journaltitle = {Educational and Psychological Measurement},
  volume = {6},
  pages = {427--438},
  issn = {0013-1644},
  doi = {10.1177/001316444600600401},
  url = {https://doi.org/10.1177/001316444600600401},
  number = {4}
}

@article{guttman_basis_1944,
  title = {A {{Basis}} for {{Scaling Qualitative Data}}},
  author = {Guttman, Louis},
  date = {1944},
  journaltitle = {American Sociological Review},
  volume = {9},
  pages = {139--150},
  issn = {00031224},
  eprint = {2086306},
  eprinttype = {jstor},
  number = {2}
}

@book{hernan_ma_causal_2019,
  title = {Causal {{Inference}}},
  author = {Hernán MA, Robins JM},
  date = {2019},
  publisher = {{Boca Raton: Chapman \& Hall/CRC, forthcoming.}},
  url = {https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}
}

@book{hooper_structural_2007,
  title = {Structural {{Equation Modeling}}: {{Guidelines}} for {{Determining Model Fit}}},
  author = {Hooper, Daire and Coughlan, Joseph and R. Mullen, Michael},
  date = {2007-11},
  volume = {6},
  pagetotal = {–}
}

@article{ioannidis_2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08},
  journaltitle = {PLoS Medicine},
  shortjournal = {PLoS Med},
  volume = {2},
  issn = {1549-1277},
  doi = {10.1371/journal.pmed.0020124},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/},
  urldate = {2020-03-03},
  abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research., Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
  eprint = {16060722},
  eprinttype = {pmid},
  file = {/home/marcos/Zotero/storage/W8YTH4T8/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf},
  number = {8},
  pmcid = {PMC1182327}
}

@article{ioannidis_2019,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2019-01-02},
  journaltitle = {CHANCE},
  volume = {32},
  pages = {4--13},
  issn = {0933-2480},
  doi = {10.1080/09332480.2019.1579573},
  url = {https://doi.org/10.1080/09332480.2019.1579573},
  urldate = {2020-03-03},
  file = {/home/marcos/Zotero/storage/2VKUBAMN/09332480.2019.html},
  number = {1}
}

@article{ioannidis_why_2016,
  title = {Why {{Most Clinical Research Is Not Useful}}},
  author = {Ioannidis, John P. A.},
  date = {2016-06},
  journaltitle = {PLOS Medicine},
  volume = {13},
  pages = {1--10},
  doi = {10.1371/journal.pmed.1002049},
  url = {https://doi.org/10.1371/journal.pmed.1002049},
  abstract = {John Ioannidis argues that problem base, context placement, information gain, pragmatism, patient centeredness, value for money, feasibility, and transparency define useful clinical research. He suggests most clinical research is not useful and reform is overdue.},
  number = {6}
}

@book{j._lee_overview_2016,
  title = {An Overview of the {{Normal Ogive Harmonic Analysis Robust Method}} ({{NOHARM}}) Approach to Item Response Theory},
  author = {J. Lee, J and Lee, Minji},
  date = {2016-01},
  volume = {12},
  pagetotal = {1–8}
}

@article{karabatsos_2001,
  title = {The {{Rasch}} Model, Additive Conjoint Measurement, and New Models of Probabilistic Measurement Theory},
  author = {Karabatsos, George},
  date = {2001},
  journaltitle = {Journal of Applied Measurement},
  shortjournal = {J Appl Meas},
  volume = {2},
  pages = {389--423},
  issn = {1529-7713},
  abstract = {This research describes some of the similarities and differences between additive conjoint measurement (a type of fundamental measurement) and the Rasch model. It seems that there are many similarities between the two frameworks, however, their differences are nontrivial. For instance, while conjoint measurement specifies measurement scales using a data-free, non-numerical axiomatic frame of reference, the Rasch model specifies measurement scales using a numerical frame of reference that is, by definition, data dependent. In order to circumvent difficulties that can be realistically imposed by this data dependence, this research formalizes new non-parametric item response models. These models are probabilistic measurement theory models in the sense that they explicitly integrate the axiomatic ideas of measurement theory with the statistical ideas of order-restricted inference and Markov Chain Monte Carlo. The specifications of these models are rather flexible, as they can represent any one of several models used in psychometrics, such as Mokken's (1971) monotone homogeneity model, Scheiblechner's (1995) isotonic ordinal probabilistic model, or the Rasch (1960) model. The proposed non-parametric item response models are applied to analyze both real and simulated data sets.},
  eprint = {12011506},
  eprinttype = {pmid},
  keywords = {Humans,Mathematical Computing,Models; Statistical,Psychological Tests,Psychometrics,Reproducibility of Results},
  langid = {english},
  number = {4}
}

@article{karabatsos_2018,
  title = {On {{Bayesian Testing}} of {{Additive Conjoint Measurement Axioms Using Synthetic Likelihood}}},
  author = {Karabatsos, George},
  date = {2018-06-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {83},
  pages = {321--332},
  issn = {1860-0980},
  doi = {10.1007/s11336-017-9581-x},
  url = {https://doi.org/10.1007/s11336-017-9581-x},
  urldate = {2019-10-05},
  abstract = {This article introduces a Bayesian method for testing the axioms of additive conjoint measurement. The method is based on an importance sampling algorithm that performs likelihood-free, approximate Bayesian inference using a synthetic likelihood to overcome the analytical intractability of this testing problem. This new method improves upon previous methods because it provides an omnibus test of the entire hierarchy of cancellation axioms, beyond double cancellation. It does so while accounting for the posterior uncertainty that is inherent in the empirical orderings that are implied by these axioms, together. The new method is illustrated through a test of the cancellation axioms on a classic survey data set, and through the analysis of simulated data.},
  keywords = {approximate Bayesian computation,axiom testing,conjoint measurement},
  langid = {english},
  number = {2}
}

@article{karabatsos_rasch_nodate,
  title = {The {{Rasch Model}}, {{Additive Conjoint Measurement}}, and {{New Models}} of {{Probabilistic Measurement Theory}}},
  author = {Karabatsos, George},
  pages = {35},
  file = {/home/marcos/Zotero/storage/STLQ2PNE/Karabatsos - The Rasch Model, Additive Conjoint Measurement, an.pdf},
  langid = {english}
}

@article{krantz_1971,
  title = {Conjoint-Measurement Analysis of Composition Rules in Psychology},
  author = {Krantz, David H. and Tversky, Amos},
  date = {1971},
  journaltitle = {Psychological Review},
  volume = {78},
  pages = {151--169},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0030637},
  abstract = {Defines composition rules as theories that describe the relationships among several measurable variables. Conjoint measurement provides methods for analyzing such rules using ordinal information only. This analysis is applied to a class of 4 composition rules in 3 variables A + P + U, (A + P)U, AP + U, APU which have been widely employed in different areas of psychology. It leads to the formulation of observable ordinal properties that can be used to test and diagnose which of the rules, if any, is appropriate for a given set of data. (45 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/home/marcos/Zotero/storage/IJWQDX3Y/1971-22010-001.html},
  keywords = {Analysis,Measurement,Theories},
  number = {2}
}

@article{kruskal_1964,
  title = {Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis},
  author = {Kruskal, J. B.},
  date = {1964-03-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {29},
  pages = {1--27},
  issn = {1860-0980},
  doi = {10.1007/BF02289565},
  url = {https://doi.org/10.1007/BF02289565},
  urldate = {2019-11-15},
  abstract = {Multidimensional scaling is the problem of representingn objects geometrically byn points, so that the interpoint distances correspond in some sense to experimental dissimilarities between objects. In just what sense distances and dissimilarities should correspond has been left rather vague in most approaches, thus leaving these approaches logically incomplete. Our fundamental hypothesis is that dissimilarities and distances are monotonically related. We define a quantitative, intuitively satisfying measure of goodness of fit to this hypothesis. Our technique of multidimensional scaling is to compute that configuration of points which optimizes the goodness of fit. A practical computer program for doing the calculations is described in a companion paper.},
  keywords = {Companion Paper,Computer Program,Multidimensional Scaling,Public Policy,Statistical Theory},
  langid = {english},
  number = {1}
}

@article{kruskal_1965,
  title = {Analysis of {{Factorial Experiments}} by {{Estimating Monotone Transformations}} of the {{Data}}},
  author = {Kruskal, J. B.},
  date = {1965},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {27},
  pages = {251--263},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1965.tb01492.x},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1965.tb01492.x},
  urldate = {2019-11-11},
  abstract = {Data may sometimes be described by a linear model with fewer terms if a transformation is applied. For example, in a factorial design the need for certain interaction terms may be eliminated by transformation. If attention is restricted to all monotone transformations, it is possible and perhaps useful to find the monotone transformation which minimizes the residual sum of squares after removing the effects explained by the model. Several sets of data from the statistical literature are analysed this way.},
  file = {/home/marcos/Zotero/storage/K8S6HGDK/j.2517-6161.1965.tb01492.html},
  langid = {english},
  number = {2}
}

@article{kyngdon_2007,
  title = {Attitudes, Order and Quantity: Deterministic and Direct Probabilistic Tests of Unidimensional Unfolding.},
  shorttitle = {Attitudes, Order and Quantity},
  author = {Kyngdon, Andrew and Richards, Ben},
  date = {2007},
  journaltitle = {Journal of applied measurement},
  volume = {8},
  pages = {1--34},
  abstract = {This article is the final in the series on unidimensional unfolding. The investigations of Kyngdon (2006b) and Michell (1994) were extended to include direct probabilistic tests of the quantitative and ordinal components of unfolding theory with the multinomial Dirichlet model (Karabatsos 2005); and tests of the higher order axiomatic conjoint measurement (ACM, Krantz, Luce, Suppes and Tversky (KLST) 1971) condition of triple cancellation. Strong Dirichlet model support for both the ordinal and quantitative components of unfolding was only found in datasets that satisfied at least double cancellation. In contrast, the Item Response Theory (IRT) simple hyperbolic cosine model for pairwise preferences (SHCMpp, Andrich 1995) fitted all datasets. The paper concluded the SHCMpp is suited to the instrumental rather than scientific task (Michell 2000) of psychological measurement; with the caveat of the problematic chi square fit statistic. The paper also presents original work by the second author on coherent tests of triple cancellation.},
  keywords = {Cautionary Warning,Clinical Trial Interactive Response Technology Documentation,Ordinal Position,Seizures,Tai Ji},
  number = {1}
}

@article{kyngdon_2008,
  title = {Conjoint {{Measurement}}, {{Error}} and the {{Rasch Model}}: {{A Reply}} to {{Michell}}, and {{Borsboom}} and {{Zand Scholten}}},
  author = {Kyngdon, Andrew},
  date = {2008-02},
  journaltitle = {Theory \& Psychology},
  volume = {18},
  pages = {125--131},
  issn = {0959-3543},
  doi = {10.1177/0959354307086927},
  url = {https://doi.org/10.1177/0959354307086927},
  abstract = {The theory of conjoint measurement was a genuine scientific revolution in measurement theory. For many years psychometricians and applied practitioners alike have contended that the Rasch model is a probabilistic version of this revolutionary theory. I disputed this claim from the perspective of representationalism. Michell's realist appraisal of the issue underscored the conclusions in my paper whilst Borsboom and Zand Scholten maintained that the Rasch model conceptually instantiates the theory of conjoint measurement. Nothing in either response refuted my conclusion. Nevertheless, relationships between the Rasch model and the theory of conjoint measurement remain an open research issue.},
  number = {1}
}

@article{lakens_equivalence_2017,
  title = {Equivalence {{Tests}}: {{A Practical Primer}} for t {{Tests}}, {{Correlations}}, and {{Meta}}-{{Analyses}}},
  author = {Lakens, Daniël},
  date = {2017},
  journaltitle = {Social Psychological and Personality Science},
  volume = {8},
  pages = {355--362},
  doi = {10.1177/1948550617697177},
  url = {https://doi.org/10.1177/1948550617697177},
  abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
  eprint = {28736600},
  eprinttype = {pmid},
  number = {4}
}

@article{lindsay_replication_2015,
  title = {Replication in {{Psychological Science}}},
  author = {Lindsay, D. Stephen},
  date = {2015-11},
  journaltitle = {Psychological Science},
  volume = {26},
  pages = {1827--1832},
  issn = {0956-7976},
  doi = {10.1177/0956797615616374},
  url = {https://doi.org/10.1177/0956797615616374},
  number = {12}
}

@article{luce_1964,
  title = {Simultaneous Conjoint Measurement: {{A}} New Type of Fundamental Measurement},
  author = {Luce, Robert Duncan and Tukey, John W.},
  date = {1964},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {1},
  pages = {1--27},
  issn = {0022-2496},
  url = {http://www.sciencedirect.com/science/article/pii/002224966490015X},
  abstract = {The essential character of what is classically considered, e.g., by N. R. Campbell, the fundamental measurement of extensive quantities is described by an axiomatization for the comparision of effects of (or responses to) arbitrary combinations of “quantities” of a single specified kind. For example, the effect of placing one arbitrary combination of masses on a pan of a beam balance is compared with another arbitrary combination on the other pan. Measurement on a ratio scale follows from such axioms. In this paper, the essential character of simultaneous conjoint measurement is described by an axiomatization for the comparision of effects of (or responses to) pairs formed from two specified kinds of “quantities”. The axioms apply when, for example, the effect of a pair consisting of one mass and one difference in gravitational potential on a device that responds to momentum is compared with the effect of another such pair. Measurement on interval scales which have a common unit follows from these axioms; usually these scales can be converted in a natural way into ratio scales. A close relation exists between conjoint measurement and the establishment of response measures in a two-way table, or other analysis-of-variance situations, for which the “effects of columns” and the “effects of rows” are additive. Indeed, the discovery of such measures, which are well known to have important practical advantages, may be viewed as the discovery, via conjoint measurement, of fundamental measures of the row and column variables. From this point of view it is natural to regard conjoint measurement as factorial measurement.},
  number = {1}
}

@article{luce_choice_1977,
  title = {The Choice Axiom after Twenty Years},
  author = {Luce, Robert Duncan},
  date = {1977},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {15},
  pages = {215--233},
  issn = {0022-2496},
  url = {http://www.sciencedirect.com/science/article/pii/0022249677900323},
  number = {3}
}

@article{mair_extended_2007,
  title = {Extended {{Rasch Modeling}}: {{The eRm Package}} for the {{Application}} of {{IRT Models}} in {{R}}},
  author = {Mair, Patrick and Hatzinger, Reinhold},
  date = {2007},
  journaltitle = {Journal of Statistical Software, Articles},
  volume = {20},
  pages = {1--20},
  issn = {1548-7660},
  doi = {10.18637/jss.v020.i09},
  url = {https://www.jstatsoft.org/v020/i09},
  number = {9}
}

@book{maydeu-olivares_multidimensional_2001,
  title = {Multidimensional {{Item Response Theory Modeling}} of {{Binary Data}}: {{Large Sample Properties}} of {{NOHARM Estimates}}},
  author = {Maydeu-Olivares, Alberto},
  date = {2001-03},
  volume = {26},
  pagetotal = {51–71}
}

@article{mayo_2017,
  title = {A {{Poor Prognosis}} for the {{Diagnostic Screening Critique}} of {{Statistical Tests}}},
  author = {Mayo, Deborah G. and Morey, Richard D.},
  date = {2017-07-26},
  url = {https://osf.io/nepx9/},
  urldate = {2020-03-04},
  abstract = {Recently, a number of statistical reformers have argued for conceptualizing significance testing as analogous to diagnostic testing, with a "base rate" of true nulls and a test's error probabilities used to compute a "positive predictive value" or "false discovery rate". These quantities are used to critique statistical and scientific practice. We argue against this; these quantities are not relevant for evaluating statistical tests, they add to the confusion over significance testing,  and they take the focus away from what matters: evidence. 
    Hosted on the Open Science Framework},
  file = {/home/marcos/Zotero/storage/WNHWMZEM/nepx9.html},
  langid = {english}
}

@incollection{mayo_error_2011,
  title = {Error {{Statistics}}},
  booktitle = {Philosophy of {{Statistics}}},
  author = {Mayo, Deborah G. and Spanos, Aris},
  editor = {Bandyopadhyay, Prasanta S. and Forster, Malcolm R.},
  date = {2011},
  volume = {7},
  pages = {153--198},
  publisher = {{North-Holland}},
  location = {{Amsterdam}},
  doi = {10.1016/B978-0-444-51862-0.50005-8},
  url = {https://www.sciencedirect.com/science/article/pii/B9780444518620500058},
  series = {Handbook of the {{Philosophy}} of {{Science}}}
}

@incollection{mayo_frequentist_2006,
  title = {Frequentist Statistics as a Theory of Inductive Inference},
  booktitle = {Optimality},
  author = {Mayo, Deborah G. and Cox, D. R.},
  editor = {Rojo, Javier},
  date = {2006},
  volume = {Number 49},
  pages = {77--97},
  publisher = {{Institute of Mathematical Statistics}},
  location = {{Beachwood, Ohio, USA}},
  doi = {10.1214/074921706000000400},
  url = {https://doi.org/10.1214/074921706000000400},
  series = {Lecture {{Notes}}–{{Monograph Series}}}
}

@article{mayo_severe_2006,
  title = {Severe {{Testing}} as a {{Basic Concept}} in a {{Neyman}}–{{Pearson Philosophy}} of {{Induction}}},
  author = {Mayo, Deborah G. and Spanos, Aris},
  date = {2006},
  journaltitle = {The British Journal for the Philosophy of Science},
  volume = {57},
  pages = {323--357},
  doi = {10.1093/bjps/axl003},
  url = {http://dx.doi.org/10.1093/bjps/axl003},
  number = {2}
}

@book{meschiari_latex2exp_2015,
  title = {Latex2exp: {{Use LaTeX Expressions}} in {{Plots}}},
  author = {Meschiari, Stefano},
  date = {2015},
  url = {https://CRAN.R-project.org/package=latex2exp}
}

@article{michell_1988,
  title = {Some Problems in Testing the Double Cancellation Condition in Conjoint Measurement},
  author = {Michell, Joel},
  date = {1988-12-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {32},
  pages = {466--473},
  issn = {0022-2496},
  doi = {10.1016/0022-2496(88)90024-7},
  url = {http://www.sciencedirect.com/science/article/pii/0022249688900247},
  urldate = {2019-11-17},
  abstract = {Two problems involved in testing the conjoint measurement condition of double cancellation are analysed. 1. It is argued that in the case of complete data matrices tests of double cancellation either confirm or falsify the hypothesis of additivity and that, contrary to popular belief, so-called “no-tests” are really acceptances. 2. It is shown that with a weak order upon 3 × 3 matrices both independence and a single test of double cancellation (which is logically independent of independence) are necessary and sufficient for additivity. Hence, if a weak order satisfies independence in such matrices only this single test of double cancellation needs to be performed.},
  file = {/home/marcos/Zotero/storage/GUQ8CVKQ/0022249688900247.html},
  langid = {english},
  number = {4}
}

@book{michell_1990,
  title = {An {{Introduction To}} the {{Logic}} of {{Psychological Measurement}}},
  author = {Michell, Joel},
  date = {1990},
  publisher = {{Psychology Press}},
  doi = {10.4324/9781315807614},
  url = {https://www.taylorfrancis.com/books/9781315807614},
  urldate = {2019-11-10},
  abstract = {This book declines to take for granted the widespread assumption that existing psychometric procedures provide scientific measurement. The currently fashionable},
  file = {/home/marcos/Zotero/storage/N67VHBRV/Michell - 2014 - An Introduction To the Logic of Psychological Meas.pdf;/home/marcos/Zotero/storage/ST3HSP5S/9781315807614.html},
  isbn = {978-1-315-80761-4},
  langid = {english}
}

@book{michell_1999,
  title = {Measurement in {{Psychology}}: {{A Critical History}} of a {{Methodological Concept}}},
  author = {Michell, Joel},
  date = {1999},
  publisher = {{Cambridge University Press}}
}

@article{michell_hölder_1996,
  title = {The {{Axioms}} of {{Quantity}} and the {{Theory}} of {{Measurement}}: {{Translated}} from {{Part I}} of {{Otto Hölder}}'s {{German Text}} “{{Die Axiome}} Der {{Quantität}} Und Die {{Lehre}} Vom {{Mass}}”},
  shorttitle = {The {{Axioms}} of {{Quantity}} and the {{Theory}} of {{Measurement}}},
  author = {Michell, Joel and Ernst, Catherine},
  date = {1996-09-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {40},
  pages = {235--252},
  issn = {0022-2496},
  doi = {10.1006/jmps.1996.0023},
  url = {http://www.sciencedirect.com/science/article/pii/S0022249696900231},
  urldate = {2019-11-17},
  file = {/home/marcos/Zotero/storage/6ADAGY2W/S0022249696900231.html},
  langid = {english},
  number = {3}
}

@article{morey_philosophy_2016,
  title = {The Philosophy of {{Bayes}} Factors and the Quantification of Statistical Evidence},
  author = {Morey, Richard D. and Romeijn, Jan-Willem and Rouder, Jeffrey N.},
  date = {2016},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {72},
  pages = {6--18},
  issn = {0022-2496},
  doi = {https://doi.org/10.1016/j.jmp.2015.11.001},
  url = {http://www.sciencedirect.com/science/article/pii/S0022249615000723},
  keywords = {Bayes factor,Hypothesis testing}
}

@article{morris_scale_2017,
  title = {Scale {{Imposition}} as {{Quantitative Alchemy}}: {{Studies}} on the {{Transitivity}} of {{Neuroticism Ratings}}},
  author = {Morris, Stefanie Dorough and Grice, James W. and Cox, Ryan A.},
  date = {2017},
  journaltitle = {Basic and Applied Social Psychology},
  volume = {39},
  pages = {1--18},
  doi = {10.1080/01973533.2016.1256288},
  url = {https://doi.org/10.1080/01973533.2016.1256288},
  number = {1}
}

@article{munafo_manifesto_2017,
  title = {A Manifesto for Reproducible Science},
  author = {Munafò, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Percie du Sert, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
  date = {2017-01},
  journaltitle = {Nature Human Behaviour},
  volume = {1},
  pages = {0021--},
  url = {http://dx.doi.org/10.1038/s41562-016-0021}
}

@article{neyman_ix._1933,
  title = {{{IX}}. {{On}} the Problem of the Most Efficient Tests of Statistical Hypotheses},
  author = {Neyman, J. and Pearson, E. S.},
  date = {1933},
  journaltitle = {Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  volume = {231},
  pages = {289--337},
  issn = {0264-3952},
  doi = {10.1098/rsta.1933.0009},
  url = {http://rsta.royalsocietypublishing.org/content/231/694-706/289},
  number = {694-706}
}

@article{nickerson_1984,
  title = {Scaling {{Distortion}} in {{Numerical Conjoint Measurement}}},
  author = {Nickerson, Carol A. and McClelland, Gary H.},
  date = {1984-04-01},
  journaltitle = {Applied Psychological Measurement},
  shortjournal = {Applied Psychological Measurement},
  volume = {8},
  pages = {183--198},
  issn = {0146-6216},
  doi = {10.1177/014662168400800207},
  url = {https://doi.org/10.1177/014662168400800207},
  urldate = {2019-11-13},
  abstract = {Proponents of numerical conjoint measurement gen erally assume that the technique's goodness-of-fit mea sure will detect an inappropriate composition rule or the presence of random response error. In this paper a number of hypothetical and real preference rank order ings are analyzed using both axiomatic conjoint mea surement and numerical conjoint measurement to dem onstrate that this assumption is not warranted and may result in a distorted scaling.},
  langid = {english},
  number = {2}
}

@online{noauthor_13_nodate,
  title = {(13) {{A Poor Prognosis}} for the {{Diagnostic Screening Critique}} of {{Statistical Tests}} | {{Request PDF}}},
  journaltitle = {ResearchGate},
  url = {https://www.researchgate.net/publication/326115851_A_Poor_Prognosis_for_the_Diagnostic_Screening_Critique_of_Statistical_Tests},
  urldate = {2020-03-04},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  file = {/home/marcos/Zotero/storage/LE6PCBHV/326115851_A_Poor_Prognosis_for_the_Diagnostic_Screening_Critique_of_Statistical_Tests.html},
  langid = {english}
}

@online{noauthor_9_nodate,
  title = {(9) {{The Rasch}} Model, Additive Conjoint Measurement, and New Probabilistic Measurement Theory},
  journaltitle = {ResearchGate},
  url = {https://www.researchgate.net/publication/11359116_The_Rasch_model_additive_conjoint_measurement_and_new_probabilistic_measurement_theory},
  urldate = {2019-11-14},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  file = {/home/marcos/Zotero/storage/SBFAWX5V/11359116_The_Rasch_model_additive_conjoint_measurement_and_new_probabilistic_measurement_theory.html},
  langid = {english}
}

@online{noauthor_axiome_nodate,
  title = {Die {{Axiome}} Der {{Quantität}} Und Die {{Lehre}} Vom {{Maß}} | {{BibSonomy}}},
  url = {https://www.bibsonomy.org/bibtex/15ef288775e18c41153620fd3d2fc2f4b/keinstein},
  urldate = {2019-11-17},
  file = {/home/marcos/Zotero/storage/L8MKI3Q3/keinstein.html}
}

@book{noauthor_physics_nodate,
  title = {Physics Elements | {{General}} and Classical Physics},
  url = {https://www.cambridge.org/jp/academic/subjects/physics/general-and-classical-physics/physics-elements, https://www.cambridge.org/jp/academic/subjects/physics/general-and-classical-physics},
  urldate = {2020-02-14},
  file = {/home/marcos/Zotero/storage/QPRDC64K/physics-elements.html},
  langid = {english}
}

@online{noauthor_scaling_nodate,
  title = {Scaling {{Distortion}} in {{Numerical Conjoint Measurement}} - {{Carol A}}. {{Nickerson}}, {{Gary H}}. {{McClelland}}, 1984},
  url = {https://journals.sagepub.com/doi/abs/10.1177/014662168400800207?journalCode=apma},
  urldate = {2019-11-13},
  file = {/home/marcos/Zotero/storage/4FFBZNXV/014662168400800207.html}
}

@online{noauthor_why_nodate,
  title = {Why {{Most Published Research Findings Are False}}},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124},
  urldate = {2020-03-03},
  file = {/home/marcos/Zotero/storage/B37RQNIP/article.html}
}

@article{nuijten_default_2015,
  title = {A Default {{Bayesian}} Hypothesis Test for Mediation},
  author = {Nuijten, Michèle B. and Wetzels, Ruud and Matzke, Dora and Dolan, Conor V. and Wagenmakers, Eric-Jan},
  date = {2015-03},
  journaltitle = {Behavior Research Methods},
  volume = {47},
  pages = {85--97},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0470-2},
  url = {https://doi.org/10.3758/s13428-014-0470-2},
  abstract = {In order to quantify the relationship between multiple variables, researchers often carry out a mediation analysis. In such an analysis, a mediator (e.g., knowledge of a healthy diet) transmits the effect from an independent variable (e.g., classroom instruction on a healthy diet) to a dependent variable (e.g., consumption of fruits and vegetables). Almost all mediation analyses in psychology use frequentist estimation and hypothesis-testing techniques. A recent exception is Yuan and MacKinnon (Psychological Methods, 14, 301–322, 2009), who outlined a Bayesian parameter estimation procedure for mediation analysis. Here we complete the Bayesian alternative to frequentist mediation analysis by specifying a default Bayesian hypothesis test based on the Jeffreys–Zellner–Siow approach. We further extend this default Bayesian test by allowing a comparison to directional or one-sided alternatives, using Markov chain Monte Carlo techniques implemented in JAGS. All Bayesian tests are implemented in the R package BayesMed (Nuijten, Wetzels, Matzke, Dolan, \& Wagenmakers, 2014).},
  number = {1}
}

@article{open_science_collaboration_estimating_2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  url = {http://science.sciencemag.org/content/349/6251/aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  number = {6251}
}

@book{oren_demonstrating_2014,
  title = {Demonstrating the Validity of Three General Scores of {{PET}} in Predicting Higher Education Achievement in {{Israel}}},
  author = {Oren, Carmel and Kennet-Cohen, Tamar and Turvall, Elliot and Allalouf, Avi},
  date = {2014-02},
  volume = {26},
  pagetotal = {117–26}
}

@book{pedersen_patchwork_2017,
  title = {Patchwork: {{The Composer}} of Ggplots},
  author = {Pedersen, Thomas Lin},
  date = {2017},
  url = {https://github.com/thomasp85/patchwork}
}

@article{perline_1979,
  title = {The {{Rasch Model}} as {{Additive Conjoint Measurement}}},
  author = {Perline, Richard and Wright, Benjamin D. and Wainer, Howard},
  date = {1979-04-01},
  journaltitle = {Applied Psychological Measurement},
  shortjournal = {Applied Psychological Measurement},
  volume = {3},
  pages = {237--255},
  issn = {0146-6216},
  doi = {10.1177/014662167900300213},
  url = {https://doi.org/10.1177/014662167900300213},
  urldate = {2019-10-10},
  abstract = {The object of this paper is to present Rasch's psychometric model as a special case of additive conjoint measurement. The connection between these two areas has been discussed before, but largely ignored. Because the theory of conjoint measurement has been formulated determinis tically, there have been some difficulties in its application. It is pointed out in this paper that the Rasch model, which is a stochastic model, does not suffer from this fault. The exposition centers on the analyses of two data sets, each of which was ana lyzed using Rasch scaling methods as well as some of the methods of conjoint measurement. The results, using the different procedures, are com pared.},
  langid = {english},
  number = {2}
}

@article{peterson_partial_1990,
  title = {Partial {{Proportional Odds Models}} for {{Ordinal Response Variables}}},
  author = {Peterson, Bercedis and Harrell, Frank E.},
  date = {1990},
  journaltitle = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {39},
  pages = {205--217},
  issn = {00359254, 14679876},
  abstract = {The ordinal logistic regression model that McCullagh calls the proportional odds model is extended to models that allow non-proportional odds for a subset of the explanatory variables. The maximum likelihood method is used for estimation of parameters of general and restricted partial proportional odds models as well as for the derivation of Wald, Rao score and likelihood ratio tests. These tests assess association without assuming proportional odds and test proportional odds against various alternatives. Simulation results compare the score test for proportional odds with tests suggested by Koch, Amara and Singer that are based on a series of binary logistic models.},
  eprint = {2347760},
  eprinttype = {jstor},
  number = {2}
}

@book{r_core_team_r_2018,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2018},
  publisher = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@online{roberts_1984,
  title = {Measurement {{Theory}}: {{With Applications}} to {{Decisionmaking}}, {{Utility}}, and the {{Social Sciences}}},
  shorttitle = {Measurement {{Theory}}},
  author = {Roberts, Fred S.},
  date = {1984},
  journaltitle = {Cambridge Core},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511759871},
  url = {/core/books/measurement-theory/7D75B72C3E5FA676EA7AD6AB4D8DF4A7},
  urldate = {2020-03-08},
  abstract = {Cambridge Core - Logic, Categories and Sets - Measurement Theory -  by Fred S. Roberts},
  file = {/home/marcos/Zotero/storage/GNFSV8ET/7D75B72C3E5FA676EA7AD6AB4D8DF4A7.html},
  isbn = {9780521302272 9780521102438 9780511759871},
  langid = {english},
  note = {Library Catalog: www.cambridge.org}
}

@article{rouder_optional_2014,
  title = {Optional Stopping: {{No}} Problem for {{Bayesians}}},
  author = {Rouder, Jeffrey N.},
  date = {2014-04},
  journaltitle = {Psychonomic Bulletin \& Review},
  volume = {21},
  pages = {301--308},
  issn = {1531-5320},
  doi = {10.3758/s13423-014-0595-4},
  url = {https://doi.org/10.3758/s13423-014-0595-4},
  abstract = {Optional stopping refers to the practice of peeking at data and then, based on the results, deciding whether or not to continue an experiment. In the context of ordinary significance-testing analysis, optional stopping is discouraged, because it necessarily leads to increased type I error rates over nominal values. This article addresses whether optional stopping is problematic for Bayesian inference with Bayes factors. Statisticians who developed Bayesian methods thought not, but this wisdom has been challenged by recent simulation results of Yu, Sprenger, Thomas, and Dougherty (2013) and Sanborn and Hills (2013). In this article, I show through simulation that the interpretation of Bayesian quantities does not depend on the stopping rule. Researchers using Bayesian methods may employ optional stopping in their own research and may provide Bayesian analysis of secondary data regardless of the employed stopping rule. I emphasize here the proper interpretation of Bayesian quantities as measures of subjective belief on theoretical positions, the difference between frequentist and Bayesian interpretations, and the difficulty of using frequentist intuition to conceptualize the Bayesian approach.},
  number = {2}
}

@article{saka_general_2016,
  title = {General {{Ability}} or {{Distinct Scholastic Aptitudes}}? {{A Multidimensional Validity Analysis}} of the {{Psychometric Higher}}-{{Education Entrance Test}}},
  author = {Saka, Dvir Kleper Noa},
  date = {2016}
}

@article{satorra_corrections_1994,
  title = {Corrections to Test Statistics and Standard Errors in Covariance Structure Analysis.},
  author = {Satorra, Albert and Bentler, Pete M.},
  date = {1994},
  journaltitle = {Latent variables analysis: Applications for developmental research.},
  pages = {399--419},
  issn = {0-8039-5330-5 (Hardcover); 0-8039-5331-3 (Paperback)},
  abstract = {A. Satorra and P. Bentler . . . developed an approach to the asymptotic behavior of covariance structure statistics that rather naturally yields corrections to the goodness-of-fit statistic of the scaling and Satterthwaite types / present these results and . . . illustrate how they improve upon the uncorrected statistics that are now implemented in the field of covariance structure analysis / [show] that the proposed corrections not only encompass the ones advocated by A. Shapiro and M. Browne (1987) in case of elliptical data but do not suffer from the drawback of Browne-Shapiro's corrections of lack of robustness against deviations from the assumption of an elliptical distribution / provides a theory for correcting the standard covariance matrix of the vector of parameter estimates (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Analysis of Covariance,*Error of Measurement,Goodness of Fit}
}

@article{scott_1964,
  title = {Measurement Structures and Linear Inequalities},
  author = {Scott, Dana},
  date = {1964-07-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {1},
  pages = {233--247},
  issn = {0022-2496},
  doi = {10.1016/0022-2496(64)90002-1},
  url = {http://www.sciencedirect.com/science/article/pii/0022249664900021},
  urldate = {2019-11-12},
  abstract = {The general mathematical criterion for the solvability of finite systems of linear inequalities is applied to some specific situations from measurement theory. Three examples are treated in detail, and in each case the necessary and sufficent conditions for existence of a suitable real-valued (utility) function on a finite structure are obtained.},
  file = {/home/marcos/Zotero/storage/7UKBUKT8/0022249664900021.html},
  langid = {english},
  number = {2}
}

@article{senn_comment_2002,
  title = {A Comment on Replication, p-Values and Evidence {{S}}.{{N}}.{{Goodman}}, {{Statistics}} in {{Medicine}} 1992; 11:875-879},
  author = {Senn, Stephen},
  date = {2002},
  journaltitle = {Statistics in Medicine},
  volume = {21},
  pages = {2437--2444},
  issn = {1097-0258},
  doi = {10.1002/sim.1072},
  url = {http://dx.doi.org/10.1002/sim.1072},
  number = {16}
}

@online{SIST_2018,
  title = {Statistical {{Inference}} as {{Severe Testing}}: {{How}} to {{Get Beyond}} the {{Statistics Wars}}},
  shorttitle = {Statistical {{Inference}} as {{Severe Testing}}},
  author = {Mayo, Deborah G.},
  date = {2018},
  journaltitle = {Cambridge Core},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781107286184},
  url = {/core/books/statistical-inference-as-severe-testing/D9DF409EF568090F3F60407FF2B973B2},
  urldate = {2020-03-19},
  abstract = {Cambridge Core - Philosophy of Science - Statistical Inference as Severe Testing -  by Deborah G. Mayo},
  file = {/home/marcos/Zotero/storage/85IP57XK/Mayo - 2018 - Statistical Inference as Severe Testing How to Ge.pdf;/home/marcos/Zotero/storage/VMR9MEHI/D9DF409EF568090F3F60407FF2B973B2.html},
  isbn = {9781107286184 9781107054134 9781107664647},
  langid = {english},
  note = {Library Catalog: www.cambridge.org}
}

@article{spearman_general_1904,
  title = {"{{General Intelligence}}," {{Objectively Determined}} and {{Measured}}},
  author = {Spearman, C.},
  date = {1904},
  journaltitle = {The American Journal of Psychology},
  volume = {15},
  pages = {201--292},
  issn = {00029556},
  eprint = {1412107},
  eprinttype = {jstor},
  number = {2}
}

@book{stan_development_team_rstan_2018,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  date = {2018},
  url = {http://mc-stan.org/}
}

@book{stan_development_team_shinystan_2017,
  title = {Shinystan: {{Interactive Visual}} and {{Numerical Diagnostics}} and {{Posterior Analysis}} for {{Bayesian Models}}.},
  author = {{Stan Development Team}},
  date = {2017},
  url = {http://mc-stan.org/}
}

@article{sterling_publication_1959,
  title = {Publication {{Decisions}} and {{Their Possible Effects}} on {{Inferences Drawn}} from {{Tests}} of {{Significance}}–{{Or Vice Versa}}},
  author = {Sterling, Theodore D.},
  date = {1959},
  journaltitle = {Journal of the American Statistical Association},
  volume = {54},
  pages = {30--34},
  issn = {01621459},
  abstract = {There is some evidence that in fields where statistical tests of significance are commonly used, research which yields nonsignificant results is not published. Such research being unknown to other investigators may be repeated independently until eventually by chance a significant result occurs-an "error of the first kind"-and is published. Significant results published in these fields are seldom verified by independent replication. The possibility thus arises that the literature of such a field consists in substantial part of false conclusions resulting from errors of the first kind in statistical tests of significance.},
  eprint = {2282137},
  eprinttype = {jstor},
  number = {285}
}

@article{stevens_1946,
  title = {On the {{Theory}} of {{Scales}} of {{Measurement}}},
  author = {Stevens, S. S.},
  date = {1946-06},
  journaltitle = {Science},
  volume = {103},
  pages = {677--},
  url = {http://science.sciencemag.org/content/103/2684/677.abstract},
  abstract = {300 Multiple ChoicesThis is a pdf-only article and there is no markup to show you.full-text.pdf},
  number = {2684}
}

@article{stevens_theory_1946-1,
  title = {On the {{Theory}} of {{Scales}} of {{Measurement}}},
  author = {Stevens, S. S.},
  date = {1946-06-07},
  journaltitle = {Science},
  volume = {103},
  pages = {677--680},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.103.2684.677},
  url = {https://science.sciencemag.org/content/103/2684/677},
  urldate = {2019-11-17},
  eprint = {17750512},
  eprinttype = {pmid},
  file = {/home/marcos/Zotero/storage/38RZ6488/677.html},
  langid = {english},
  number = {2684}
}

@article{tate_comparison_2003,
  title = {A {{Comparison}} of {{Selected Empirical Methods}} for {{Assessing}} the {{Structure}} of {{Responses}} to {{Test Items}}},
  author = {Tate, Richard},
  date = {2003-05},
  journaltitle = {Applied Psychological Measurement},
  volume = {27},
  pages = {159--203},
  issn = {0146-6216},
  doi = {10.1177/0146621603027003001},
  url = {https://doi.org/10.1177/0146621603027003001},
  abstract = {Selected methods of empirically assessing the structure of tests with dichotomous items were compared. The methods included both exploratory and confirmatory procedures from two different families, those based on parametric models and nonparametric methods based on conditional item covariances. The analysis conditions considered were typical of large-scale assessments, for example, the tests were composed of a relatively large number of items, and it was assumed that a relatively large sample size would be available for analysis. Comparisons of the methods were conducted for real data from a 62-item test of reading ability and for computer-generated data for multiple unidimensional and multidimensional cases. For the most part, all methods performed reasonably well over a relatively wide range of conditions. The several exceptions to this outcome occurred when the test data departed appreciably from the assumptions or inherent limitations associated with a method, for example, when guessing was present but not allowed for in the analysis or when the multidimensional test structure was nonsimple but the goal of the method was to estimate the amount of multidimensional simple structure. Index terms: test structure, test dimensionality, local item dependencies, test factors.},
  number = {3}
}

@book{textor_dagitty_2016,
  title = {Dagitty: {{Graphical Analysis}} of {{Structural Causal Models}}},
  author = {Textor, Johannes and van der Zander, Benito},
  date = {2016},
  url = {https://CRAN.R-project.org/package=dagitty}
}

@article{thurstone_1927,
  title = {A Law of Comparative Judgment},
  author = {Thurstone, L. L.},
  date = {1927},
  journaltitle = {Psychological Review},
  volume = {34},
  pages = {273--286},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0070288},
  abstract = {A new psychological law, called the law of comparative judgment, is presented with some of its special applications in the measurement of psychological values. This law is applicable not only to the comparison of physical stimulus intensities but also to qualitative comparative judgments, such as those of excellence of specimens in an educational scale. It should be possible also to verify it on comparative judgments which involve simultaneous and successive contrast. The law is stated as follows:[Equation omitted]in which S1 and S2 are the psychological scale values of the two compared stimuli; x12 is the sigma value corresponding to the proportion of judgments p1 {$>$} p2. ς1 is the discriminal dispersion of stimulus R1 and ς2 is the dispersion of stimulus R2. r is the correlation between the discriminal deviations of R1 and R2 in the same judgment. This law is basic for work on Weber's and Fechner's laws, applies to the judgments of a single observer who compares a series of stimuli by the method of paired comparisons when no "equal" judgments are allowed, and is a rational equation for the method of constant stimuli. The law is then applied to five cases each of which involves different assumptions and different degrees of simplification of the law for practical use. The weighting of the observation equations is discussed because the observation equations obtained with the five cases are not of the same reliability and hence should not be equally weighted. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/home/marcos/Zotero/storage/JH5VCQCH/1928-00527-001.html},
  keywords = {Judgment,Values},
  number = {4}
}

@article{thurstone_criterion_1955,
  title = {The {{Criterion Problem}} in {{Personality Research}}},
  author = {Thurstone, L.L.},
  date = {1955-12},
  journaltitle = {Educational and Psychological Measurement},
  volume = {15},
  pages = {353--361},
  issn = {0013-1644},
  doi = {10.1177/001316445501500403},
  url = {https://doi.org/10.1177/001316445501500403},
  number = {4}
}

@article{trafimow_editorial_2015,
  title = {Editorial},
  author = {Trafimow, David and Marks, Michael},
  date = {2015},
  journaltitle = {Basic and Applied Social Psychology},
  volume = {37},
  pages = {1--2},
  doi = {10.1080/01973533.2015.1012991},
  url = {https://doi.org/10.1080/01973533.2015.1012991},
  number = {1}
}

@article{trendler_conjoint_2018,
  title = {Conjoint Measurement Undone},
  author = {Trendler, Günter},
  date = {2018-08},
  journaltitle = {Theory \& Psychology},
  pages = {0959354318788729--},
  issn = {0959-3543},
  doi = {10.1177/0959354318788729},
  url = {https://doi.org/10.1177/0959354318788729},
  abstract = {According to classical measurement theory, fundamental measurement necessarily requires the operation of concatenation qua physical addition. Quantities which do not allow this operation are measurable only indirectly by means of derived measurement. Since only extensive quantities sustain the operation of physical addition, measurement in psychology has been considered problematic. In contrast, the theory of conjoint measurement, as developed in representational measurement theory, proposes that the operation of ordering is sufficient for establishing fundamental measurement. The validity of this view is questioned. The misconception about the advantages of conjoint measurement, it is argued, results from the failure to notice that magnitudes of derived quantities cannot be determined directly, i.e., without the help of associated quantitative indicators. This takes away the advantages conjoint measurement has over derived measurement, making it practically useless.}
}

@article{valenzuela_brain_2008,
  title = {Brain Reserve and the Prevention of Dementia},
  author = {Valenzuela, Michael J},
  date = {2008},
  journaltitle = {Current Opinion in Psychiatry},
  volume = {21},
  pages = {--},
  issn = {0951-7367},
  url = {https://journals.lww.com/co-psychiatry/Fulltext/2008/05000/Brain_reserve_and_the_prevention_of_dementia.14.aspx},
  abstract = {Purpose of review To evaluate and synthesize recent evidence linking mental activity and dementia risk, which commonly invokes ‘brain reserve’ as the mediating construct. Recent findings Brain reserve has acquired several interpretations; however, the most reliable and practical definition focuses at the behavioural level by assessing frequency and range of participation in complex mental activities. Epidemiological research suggests a clear and consistent link of high brain reserve with reduced dementia risk. Furthermore, emerging clinical trials of cognitive exercise suggest that it may be effective for the prevention of longitudinal cognitive and functional decline. Recent animal studies implicate several mechanisms, including disease-dependent and disease-independent compensatory pathways. Summary Given the precipitous forecasts for dementia over the coming decades, effective preventive strategies are of utmost importance. Findings from brain reserve studies now meet many of the formal criteria for causal agency between complex mental activity and reduced dementia risk. Key clinical trials are therefore under way to test these claims and results are keenly awaited.},
  keywords = {brain reserve,cognitive exercise,dementia,mental activities,prevention},
  number = {3}
}

@article{vanderweele_brief_2016,
  title = {Brief {{Report}}: {{Mediation Analysis}} with an {{Ordinal Outcome}}},
  author = {VanderWeele, Tyler J. and Zhang, Yun and Lim, Pilar},
  date = {2016},
  journaltitle = {Epidemiology},
  volume = {27},
  pages = {--},
  issn = {1044-3983},
  url = {https://journals.lww.com/epidem/Fulltext/2016/09000/Brief_Report___Mediation_Analysis_with_an_Ordinal.8.aspx},
  abstract = {The article presents concepts and methods for mediation analysis for an ordinal outcome. We give definitions of natural direct and indirect effects using counterfactuals for ordinal outcomes; in this context, there are potentially different effects for any two levels of the outcome, and we consider difference and ratio scales. The confounding assumptions required for identification are similar to that in the existing mediation analysis literature. We discuss different modeling strategies for estimation. Under a proportional odds model with a reference category that is common, the direct and indirect effects on a ratio scale can each be summarized by a single estimate and are available in closed form; otherwise the effects may differ across categories compared and can be obtained by numeric simulation methods.},
  number = {5}
}

@book{vehtari_loo_2018,
  title = {Loo: {{Efficient}} Leave-One-out Cross-Validation and {{WAIC}} for {{Bayesian}} Models},
  author = {Vehtari, Aki and Gabry, Jonah and Yao, Yuling and Gelman, Andrew},
  date = {2018},
  url = {https://CRAN.R-project.org/package=loo}
}

@article{verghese_leisure_2003,
  title = {Leisure {{Activities}} and the {{Risk}} of {{Dementia}} in the {{Elderly}}},
  author = {Verghese, Joe and Lipton, Richard B. and Katz, Mindy J. and Hall, Charles B. and Derby, Carol A. and Kuslansky, Gail and Ambrose, Anne F. and Sliwinski, Martin and Buschke, Herman},
  date = {2003},
  journaltitle = {New England Journal of Medicine},
  volume = {348},
  pages = {2508--2516},
  doi = {10.1056/NEJMoa022252},
  url = {https://doi.org/10.1056/NEJMoa022252},
  eprint = {12815136},
  eprinttype = {pmid},
  number = {25}
}

@article{wason_failure_1960,
  title = {On the {{Failure}} to {{Eliminate Hypotheses}} in a {{Conceptual Task}}},
  author = {Wason, P. C.},
  date = {1960-07},
  journaltitle = {Quarterly Journal of Experimental Psychology},
  volume = {12},
  pages = {129--140},
  issn = {0033-555X},
  doi = {10.1080/17470216008416717},
  url = {http://journals.sagepub.com/doi/abs/10.1080/17470216008416717},
  abstract = {This investigation examines the extent to which intelligent young adults seek (i) confirming evidence alone (enumerative induction) or (ii) confirming and discontinuing evidence (eliminative induction), in order to draw conclusions in a simple conceptual task. The experiment is designed so that use of confirming evidence alone will almost certainly lead to erroneous conclusions because (i) the correct concept is entailed by many more obvious ones, and (ii) the universe of possible instances (numbers) is infinite.Six out of 29 subjects reached the correct conclusion without previous incorrect ones, 13 reached one incorrect conclusion, nine reached two or more incorrect conclusions, and one reached no conclusion. The results showed that those subjects, who reached two or more incorrect conclusions, were unable, or unwilling to test their hypotheses. The implications are discussed in relation to scientific thinking. This investigation examines the extent to which intelligent young adults seek (i) confirming evidence alone (enumerative induction) or (ii) confirming and discontinuing evidence (eliminative induction), in order to draw conclusions in a simple conceptual task. The experiment is designed so that use of confirming evidence alone will almost certainly lead to erroneous conclusions because (i) the correct concept is entailed by many more obvious ones, and (ii) the universe of possible instances (numbers) is infinite.Six out of 29 subjects reached the correct conclusion without previous incorrect ones, 13 reached one incorrect conclusion, nine reached two or more incorrect conclusions, and one reached no conclusion. The results showed that those subjects, who reached two or more incorrect conclusions, were unable, or unwilling to test their hypotheses. The implications are discussed in relation to scientific thinking.},
  number = {3}
}

@book{wickham_ggplot2_2016,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  date = {2016},
  publisher = {{Springer-Verlag New York}},
  url = {http://ggplot2.org},
  isbn = {978-3-319-24277-4}
}

@book{wickham_tidyverse_2017,
  title = {Tidyverse: {{Easily Install}} and {{Load}} the '{{Tidyverse}}'},
  author = {Wickham, Hadley},
  date = {2017},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@article{wilson_relation_2007,
  title = {Relation of Cognitive Activity to Risk of Developing {{Alzheimer}} Disease},
  author = {Wilson, R. S. and Scherr, P. A. and Schneider, J. A. and Tang, Y. and Bennett, D. A.},
  date = {2007},
  journaltitle = {Neurology},
  volume = {69},
  pages = {1911--1920},
  issn = {0028-3878},
  doi = {10.1212/01.wnl.0000271087.67782.cb},
  url = {http://n.neurology.org/content/69/20/1911},
  abstract = {Background: Frequent cognitive activity in old age has been associated with reduced risk of Alzheimer disease (AD), but the basis of the association is uncertain. Methods: More than 700 old people underwent annual clinical evaluations for up to 5 years. At baseline, they rated current and past frequency of cognitive activity with the current activity measure administered annually thereafter. Those who died underwent a uniform postmortem examination of the brain. Amyloid burden, density of tangles, and presence of Lewy bodies were assessed in eight brain regions and the number of chronic cerebral infarctions was noted. Results: During follow-up, 90 people developed AD. More frequent participation in cognitive activity was associated with reduced incidence of AD (HR = 0.58; 95\% CI: 0.44, 0.77); a cognitively inactive person (score = 2.2, 10th percentile) was 2.6 times more likely to develop AD than a cognitively active person (score = 4.0, 90th percentile). The association remained after controlling for past cognitive activity, lifespan socioeconomic status, current social and physical activity, and low baseline cognitive function. Frequent cognitive activity was also associated with reduced incidence of mild cognitive impairment and less rapid decline in cognitive function. Among 102 persons who died and had a brain autopsy, neither global nor regionally specific measures of neuropathology were related to level of cognitive activity before the study, at study onset, or during the course of the study. Conclusion: Level of cognitively stimulating activity in old age is related to risk of developing dementia. GLOSSARY: AD = Alzheimer disease; MCI = mild cognitive impairment.},
  number = {20}
}

@article{yates_influence_1951,
  title = {The {{Influence}} of {{Statistical Methods}} for {{Research Workers}} on the {{Development}} of the {{Science}} of {{Statistics}}},
  author = {Yates, F.},
  date = {1951},
  journaltitle = {Journal of the American Statistical Association},
  volume = {46},
  pages = {19--34},
  doi = {10.1080/01621459.1951.10500764},
  url = {https://doi.org/10.1080/01621459.1951.10500764},
  number = {253}
}

@book{yee_vgam_2018,
  title = {{{VGAM}}: {{Vector Generalized Linear}} and {{Additive Models}}},
  author = {Yee, Thomas W.},
  date = {2018},
  url = {https://CRAN.R-project.org/package=VGAM}
}


