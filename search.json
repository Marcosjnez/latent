[{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcos JimÃ©nez. Maintainer. Mauricio Garnier-Villarreal. . Vithor R. Franco. .","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"JimÃ©nez M, Garnier-Villarreal M, Franco VR (2025). latent: R package Latent Variable Modeling. R package version 0.1.0, https://github.com/Marcosjnez/latent.","code":"@Manual{,   title = {latent: An R package for Latent Variable Modeling},   author = {Marcos JimÃ©nez and Mauricio Garnier-Villarreal and Vithor R. Franco},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/Marcosjnez/latent}, }"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-windows-and-linux","dir":"","previous_headings":"","what":"An R package for Latent Class and Factor Analysis Models","title":"An R package for Latent Class and Factor Analysis Models","text":"","code":"devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Class and Factor Analysis Models","text":"Install macrtools R package James Balamuta: Install Command Line Tools R Compilation Toolchain (take minutes): Get OpenMP support: difficulties installation, check following resources: https://mac.thecoatlessprofessor.com/macrtools/index.html https://mac.thecoatlessprofessor.com/macrtools/reference/openmp.html Finally,","code":"# install.packages(\"remotes\") remotes::install_github(\"coatless-mac/macrtools\") macrtools::macos_rtools_install() macrtools::openmp_install() devtools::install_github(\"marcosjnez/latent\")"},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/index.html","id":"latent-latent-class-and-factor-analysis-models","dir":"","previous_headings":"","what":"latent: Latent Class and Factor Analysis Models","title":"An R package for Latent Class and Factor Analysis Models","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-windows-and-linux-1","dir":"","previous_headings":"","what":"Installation in Windows and Linux","title":"An R package for Latent Class and Factor Analysis Models","text":"","code":"devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos-1","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Class and Factor Analysis Models","text":"Install macrtools R package James Balamuta: Install Command Line Tools R Compilation Toolchain (take minutes): Get OpenMP support: difficulties installation, check following resources: https://mac.thecoatlessprofessor.com/macrtools/index.html https://mac.thecoatlessprofessor.com/macrtools/reference/openmp.html Finally,","code":"# install.packages(\"remotes\") remotes::install_github(\"coatless-mac/macrtools\") macrtools::macos_rtools_install() macrtools::openmp_install() devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"funding-1","dir":"","previous_headings":"","what":"Funding","title":"An R package for Latent Class and Factor Analysis Models","text":"package development supported â€œDYNANSE: Righting Wrongs. Life Course Dynamics Approach Non-Standard Employmentâ€ project, received funding European Research Council (ERC) European Unionâ€™s Horizon 2020 research innovation programme (grant agreement 864471). >>>>>>> ec5a59b8cde613fd9651922dc52b2f9ef46a45da","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"dataset lavaan R package.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"","code":"HolzingerSwineford1939"},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"data frame 301 rows 15 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"Fit Confirmatory Factor Analysis (CFA) model lavaan syntax.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"","code":"cfast(data, model = NULL, cor = \"pearson\", estimator = \"ml\", group = NULL, sample.cov = NULL, nobs = NULL, missing = \"pairwise.complete.obs\", W = NULL, std.lv = FALSE, positive = FALSE, do.fit = TRUE, control = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"","code":"if (FALSE) { # \\dontrun{ # The famous Holzinger and Swineford (1939) example HS.model <- ' visual  =~ x1 + x2 + x3               textual =~ x4 + x5 + x6               speed   =~ x7 + x8 + x9 '  fit <- cfast(model = HS.model, data = HolzingerSwineford1939) summary(fit, fit.measures = TRUE) } # }"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: empathy â€” empathy","title":"Example dataset: empathy â€” empathy","text":"dataset tidySEM R package 467 rows 13 columns. first 6 columns continuous item responses.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: empathy â€” empathy","text":"","code":"empathy"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: empathy â€” empathy","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: empathy â€” empathy","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” getfit","title":"Fit indices â€” getfit","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” getfit","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” getfit","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” getfit","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” getfit","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” getfit","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: gss82 â€” gss82","title":"Example dataset: gss82 â€” gss82","text":"dataset poLCA R package 1202 rows 4 columns. Items dichotomous polytomous.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: gss82 â€” gss82","text":"","code":"gss82"},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: gss82 â€” gss82","text":"data frame 1202 rows 4 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: gss82 â€” gss82","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":null,"dir":"Reference","previous_headings":"","what":"An R package for Latent Variable Modeling â€” latent-package","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An R package for Latent Variable Modeling â€” latent-package","text":"DESCRIPTION file: package yet installed build time.   Index:  package yet installed build time.  ~~ overview use package, including important functions ~~","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Marcos JimÃ©nez [fnd, cre],   Mauricio Garnier-Villarreal [cre],   Vithor R. Franco [cre] Maintainer: Marcos JimÃ©nez <m.j.jimenezhenriquez@vu.nl>, Mauricio Garnier-Villarreal <m.garniervillarreal@vu.nl>, Vithor R. Franco <vithorfranco@gmail.com>","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An R package for Latent Variable Modeling â€” latent-package","text":"~~ Literature references background information ~~","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An R package for Latent Variable Modeling â€” latent-package","text":"","code":"# simple examples of the most important functions"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. â€” lca","title":"Latent Class Analysis. â€” lca","text":"Estimate latent class models gaussian multinomial item models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. â€” lca","text":"","code":"lca(data, item = rep(\"gaussian\", ncol(data)), nclasses = 2L, model = NULL,     do.fit = TRUE, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. â€” lca","text":"data data frame matrix. nclasses Number latent classes. item Character vector model item (.e., \"gaussian\" \"multinomial\"). Defaults \"gaussian\" items. model List parameter labels. See 'details' information. control List control parameters optimization algorithm. See 'details' information. .fit TRUE fit model FALSE return model setup. Defaults TRUE.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. â€” lca","text":"List following objects: parameters model logarithm probabilities classes. f Logarithm likelihood maximum.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. â€” lca","text":"lca estimates models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. â€” lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. â€” print.lca","title":"Latent Class Analysis. â€” print.lca","text":"Print information latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. â€” print.lca","text":"","code":"lca(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. â€” print.lca","text":"model Character vector model item.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. â€” print.lca","text":"Stuff: df Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. â€” print.lca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. â€” print.lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors â€” se","title":"Standard Errors â€” se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors â€” se","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors â€” se","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors â€” se","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors â€” se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors â€” se","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the default model for Latent Class Analysis. â€” setup_lca","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"Get default model Latent Class Analysis.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"","code":"setup_lca(data, item, nclasses, model, control)"},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"data data.frame matrix response. nclasses Number latent classes. item Character vector model item. model List parameter labels. See 'details' information. constraints model checked identification? Defaults TRUE.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"List following objects: none . none .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"get_lca generates model probability belonging classes conditional response probabilities. models may modified user set equality constraints fix parameters.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/setup_lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get the default model for Latent Class Analysis. â€” setup_lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate factor structures with misspecification errors. â€” simfactor","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"Simulate factor bifactor structures crossloadings, correlated factors, .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"","code":"simfactor(nfactors = 5, nitems = 6, loadings = \"medium\", crossloadings = 0, correlations = 0, estimator = \"minres\", fit = \"rmsr\", misfit = 0, error_method = \"cudeck\", efa = FALSE, ngenerals = 0, loadings_g = \"medium\", correlations_g = 0, pure = FALSE, lambda = NULL, Phi = NULL, Psi = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"nfactors Number factors. nitems Number items per factor. loadings Loadings' magnitude factors: \"low\", \"medium\" \"high\". Defaults \"medium\". crossloadings Magnitude cross-loadings among group factors. Defaults 0. correlations_g Correlation among general factors. Defaults 0. correlations Correlation among factors. Defaults 0. estimator estimator used generate population error: \"minres\" \"ml\". fit Fit index control population error. misfit Misfit value generate population error. error_method Method used control population error: c(\"yuan\", \"cudeck\"). Defaults \"cudeck\". efa Reproduce error EFA CFA. Defaults FALSE (CFA). ngenerals Number general factors. loadings_g Loadings' magnitude general factors: \"low\", \"medium\" \"high\". Defaults \"medium\". pure Fix pure item general factor. Defaults FALSE. lambda Custom loading matrix. Phi NULL, factors correlated value given correlations. Phi Custom Phi matrix. lambda NULL, Phi conformable loading matrix specified arguments. Psi Custom Psi matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"List following objects: lambda Population loading matrix. Phi Population factor correlation matrix. Psi Population covariance matrix errors. R Model correlation matrix. R_error Model correlation matrix misspecification errors. uniquenesses Population uniquenesses. delta Minimum loss function correspond misfit value.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"simfactor generates bi-factor generalized bifactor patterns cross-loadings, pure items correlations among general group factors. crossloading different 0, one cross-loading introduced item pertaining group factor. pure TRUE, one item loading group factor removed item loads entirely general factor. maintain item communalities constant upon modifications, item loading factors may shrunk (adding cross-loadings) increase (setting pure items). Loading magnitudes may range 0.3-0.5 (\"low\"), 0.4-0.6 (\"medium\") 0.5-0.7 (\"high\"). Custom ranges can supplied vectors (.e., c(0.2, 0.5))","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"Cudeck, R., & Browne, M. W. (1992). Constructing covariance matrix yields specified minimizer specified minimum discrepancy function value. Psychometrika, 57(3), 357â€“369. doi:10.1007/BF02295424 JimÃ©nez, M., Abad, F. J., Garcia-Garzon, E., & Garrido, L. E. (2023). Exploratory Bi-factor Analysis Multiple General Factors. Multivariate Behavioral Research, 58(6), 1072â€“1089. doi:10.1080/00273171.2023.2189571 JimÃ©nez, M., Abad, F. J., Garcia-Garzon, E., Golino, H., Christensen, . P., & Garrido, L. E. (2023). Dimensionality assessment bifactor structures multiple general factors: network psychometrics approach. Psychological Methods. Advance online publication. doi:10.1037/met0000590 Yuan, K.-H., & Hayashi, K. (2003). Bootstrap approach inference power analysis based three test statistics covariance structure models. British Journal Mathematical Statistical Psychology, 56(1), 93â€“110. doi:10.1348/000711003321645368","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"","code":"# Simulate data: sim <- simfactor(nfactors = 3, nitems = 4, correlations = 0.40,                  crossloadings = 0.30) sim$lambda #>               S1        S2        S3 #> item1  0.4995555 0.0000000 0.3000000 #> item2  0.4579534 0.0000000 0.0000000 #> item3  0.5465764 0.0000000 0.0000000 #> item4  0.5545043 0.0000000 0.0000000 #> item5  0.3000000 0.5749201 0.0000000 #> item6  0.0000000 0.4349881 0.0000000 #> item7  0.0000000 0.4068483 0.0000000 #> item8  0.0000000 0.4640771 0.0000000 #> item9  0.0000000 0.3000000 0.4804656 #> item10 0.0000000 0.0000000 0.4391340 #> item11 0.0000000 0.0000000 0.4807076 #> item12 0.0000000 0.0000000 0.4127323 sim$Phi #>      [,1] [,2] [,3] #> [1,]  1.0  0.4  0.4 #> [2,]  0.4  1.0  0.4 #> [3,]  0.4  0.4  1.0 scores <- MASS::mvrnorm(1e3, rep(0, nrow(sim$R_error)), Sigma = sim$R_error) s <- cor(scores)"},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: values â€” values","title":"Example dataset: values â€” values","text":"dataset poLCA R package 216 rows 4 columns. 4 columns dichotomous items.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: values â€” values","text":"","code":"values"},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: values â€” values","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: values â€” values","text":"Generated example","code":""}]
