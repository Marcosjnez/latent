[{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcos Jiménez. Maintainer. Mauricio Garnier-Villarreal. . Vithor R. Franco. .","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jiménez M, Garnier-Villarreal M, Franco VR (2025). latent: R package Latent Variable Modeling. R package version 0.1.0, https://github.com/Marcosjnez/latent.","code":"@Manual{,   title = {latent: An R package for Latent Variable Modeling},   author = {Marcos Jiménez and Mauricio Garnier-Villarreal and Vithor R. Franco},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/Marcosjnez/latent}, }"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"latent-latent-class-and-factor-analysis-models","dir":"","previous_headings":"","what":"An R package for Latent Class and Factor Analysis Models","title":"An R package for Latent Class and Factor Analysis Models","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-windows-and-linux","dir":"","previous_headings":"","what":"Installation in Windows and Linux","title":"An R package for Latent Class and Factor Analysis Models","text":"","code":"devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Class and Factor Analysis Models","text":"Install Command Line Tools: Install Homebrew: Install OpenMP support: Update Makevars Intel Macs: Apple Silicon Macs (make sure goes end file): Finally,","code":"xcode-select --install /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" brew update && brew install libomp add the following lines to ~/.R/Makevars. CPPFLAGS += -Xclang -fopenmp LDFLAGS += -lomp LDFLAGS += -L/opt/homebrew/opt/libomp/lib -lomp CPPFLAGS += -I/opt/homebrew/opt/libomp/include -Xclang -fopenmp devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"An R package for Latent Class and Factor Analysis Models","text":"package development supported “DYNANSE: Righting Wrongs. Life Course Dynamics Approach Non-Standard Employment” project, received funding European Research Council (ERC) European Union’s Horizon 2020 research innovation programme (grant agreement 864471).","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirmatory factor analysis. — cfast","title":"Confirmatory factor analysis. — cfast","text":"Confirmatory factor analysis.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirmatory factor analysis. — cfast","text":"","code":"cfast(   data,   model = NULL,   lambda = NULL,   phi = NULL,   psi = NULL,   cor = \"pearson\",   estimator = \"uls\",   rotate = NULL,   missing = \"pairwise.complete.obs\",   nobs = NULL,   group = NULL,   invariance = \"none\",   control = NULL,   std.lv = FALSE,   positive = FALSE,   do.fit = TRUE )"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices — getfit","title":"Fit indices — getfit","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices — getfit","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices — getfit","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices — getfit","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices — getfit","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices — getfit","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the default model for Latent Class Analysis. — getmodel","title":"Get the default model for Latent Class Analysis. — getmodel","text":"Get default model Latent Class Analysis.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the default model for Latent Class Analysis. — getmodel","text":"","code":"getmodel(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L)"},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the default model for Latent Class Analysis. — getmodel","text":"data data.frame matrix response. item Character vector model item. nclasses Number latent classes. model List parameter labels. See 'details' information. constraints model checked identification? Defaults TRUE.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the default model for Latent Class Analysis. — getmodel","text":"List following objects: none . none .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the default model for Latent Class Analysis. — getmodel","text":"getmodel generates model probability belonging classes conditional response probabilities. models may modified user set equality constraints fix parameters.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get the default model for Latent Class Analysis. — getmodel","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":null,"dir":"Reference","previous_headings":"","what":"An R package for Latent Variable Modeling — latent-package","title":"An R package for Latent Variable Modeling — latent-package","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An R package for Latent Variable Modeling — latent-package","text":"DESCRIPTION file: package yet installed build time.   Index:  package yet installed build time.  ~~ overview use package, including important functions ~~","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An R package for Latent Variable Modeling — latent-package","text":"Marcos Jiménez [fnd, cre],   Mauricio Garnier-Villarreal [cre],   Vithor R. Franco [cre] Maintainer: Marcos Jiménez <m.j.jimenezhenriquez@vu.nl>, Mauricio Garnier-Villarreal <m.garniervillarreal@vu.nl>, Vithor R. Franco <vithorfranco@gmail.com>","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An R package for Latent Variable Modeling — latent-package","text":"~~ Literature references background information ~~","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An R package for Latent Variable Modeling — latent-package","text":"","code":"# simple examples of the most important functions"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. — lca","title":"Latent Class Analysis. — lca","text":"Estimate latent class models gaussian multinomial item models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. — lca","text":"","code":"lca(data, item = rep(\"gaussian\", ncol(data)), nclasses = 2L, model = NULL, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L), do.fit = TRUE, constraints = TRUE)"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. — lca","text":"data data frame matrix. nclasses Number latent classes. item Character vector model item (.e., \"gaussian\" \"multinomial\"). Defaults \"gaussian\" items. model List parameter labels. See 'details' information. control List control parameters optimization algorithm. See 'details' information. .fit TRUE fit model FALSE return model setup. Defaults TRUE. constraints model checked identification? Defaults TRUE.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. — lca","text":"List following objects: parameters model logarithm probabilities classes. f Logarithm likelihood maximum.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. — lca","text":"lca estimates models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. — lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. — print.lca","title":"Latent Class Analysis. — print.lca","text":"Print information latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. — print.lca","text":"","code":"lca(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. — print.lca","text":"model Character vector model item.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. — print.lca","text":"Stuff: df Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. — print.lca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. — print.lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — se","title":"Standard Errors — se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — se","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — se","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — se","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors — se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors — se","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate factor structures with misspecification errors. — simfactor","title":"Simulate factor structures with misspecification errors. — simfactor","text":"Simulate factor bifactor structures crossloadings, correlated factors, .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate factor structures with misspecification errors. — simfactor","text":"","code":"simfactor(nfactors = 5, nitems = 6, loadings = \"medium\", crossloadings = 0, correlations = 0, estimator = \"minres\", fit = \"rmsr\", misfit = 0, error_method = \"cudeck\", efa = FALSE, ngenerals = 0, loadings_g = \"medium\", correlations_g = 0, pure = FALSE, lambda = NULL, Phi = NULL, Psi = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate factor structures with misspecification errors. — simfactor","text":"nfactors Number factors. nitems Number items per factor. loadings Loadings' magnitude factors: \"low\", \"medium\" \"high\". Defaults \"medium\". crossloadings Magnitude cross-loadings among group factors. Defaults 0. correlations_g Correlation among general factors. Defaults 0. correlations Correlation among factors. Defaults 0. estimator estimator used generate population error: \"minres\" \"ml\". fit Fit index control population error. misfit Misfit value generate population error. error_method Method used control population error: c(\"yuan\", \"cudeck\"). Defaults \"cudeck\". efa Reproduce error EFA CFA. Defaults FALSE (CFA). ngenerals Number general factors. loadings_g Loadings' magnitude general factors: \"low\", \"medium\" \"high\". Defaults \"medium\". pure Fix pure item general factor. Defaults FALSE. lambda Custom loading matrix. Phi NULL, factors correlated value given correlations. Phi Custom Phi matrix. lambda NULL, Phi conformable loading matrix specified arguments. Psi Custom Psi matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate factor structures with misspecification errors. — simfactor","text":"List following objects: lambda Population loading matrix. Phi Population factor correlation matrix. Psi Population covariance matrix errors. R Model correlation matrix. R_error Model correlation matrix misspecification errors. uniquenesses Population uniquenesses. delta Minimum loss function correspond misfit value.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate factor structures with misspecification errors. — simfactor","text":"simfactor generates bi-factor generalized bifactor patterns cross-loadings, pure items correlations among general group factors. crossloading different 0, one cross-loading introduced item pertaining group factor. pure TRUE, one item loading group factor removed item loads entirely general factor. maintain item communalities constant upon modifications, item loading factors may shrunk (adding cross-loadings) increase (setting pure items). Loading magnitudes may range 0.3-0.5 (\"low\"), 0.4-0.6 (\"medium\") 0.5-0.7 (\"high\"). Custom ranges can supplied vectors (.e., c(0.2, 0.5))","code":""},{"path":[]}]
