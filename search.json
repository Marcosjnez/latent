[{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class Model","text":"Latent Class Analysis assumes people belong different groups (.e., classes) due nonobservable characteristics. latent class model, aim estimate two kinds probabilities: probability person belongs particular class. conditional probabilities item responses person belongs given class.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class Model","text":"Suppose sample people respond JJ items 𝐲\\mathbf{y} vector contains scores item jj. Let KK denote number latent classes let xkx_k class kk. , likelihood response pattern 𝐲\\mathbf{y}, observed nn times sample every person responds independently , can written ℓ=P(𝐲)n=(∑k=1KP(xk)P(𝐲∣xk))n. \\ell \\;=\\; P(\\mathbf{y})^{n} \\;=\\; \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, P(\\mathbf{y}\\mid x_k)\\Bigg)^{n}. Assuming local independence (responses within person independent conditional class), P(𝐲∣xk)=∏j=1JP(yj∣xk), P(\\mathbf{y}\\mid x_k) \\;=\\; \\prod_{j=1}^{J} P(y_j \\mid x_k),  yjy_j denotes score item jj. Hence, ℓ=(∑k=1KP(xk)∏j=1JP(yj∣xk))n, \\ell \\;=\\; \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k)\\Bigg)^{\\!n},  log-likelihood becomes ℓℓ=nlog(∑k=1KP(xk)∏j=1JP(yj∣xk)). \\ell\\ell \\;=\\; n \\log \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k)\\Bigg).  term inside parenthesis probability single pattern, P(𝐲)P(\\mathbf{y}). Assuming independence people different response patterns, log-likelihood whole sample sum log-likelihoods response pattern. simplify computation logarithm likelihood related derivatives, let lym∣xg=logP(ym∣xg)l_{y_m \\mid x_g} = \\log P(y_m \\mid x_g), ℓℓ=nlog(∑k=1KP(xk)exp(∑j=1Jlym∣xg)). \\ell\\ell \\;=\\; n \\log \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\exp\\bigg(\\sum_{j=1}^{J} l_{y_m \\mid x_g}\\bigg)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class Model","text":"fixed pattern 𝐲\\mathbf{y}, define P(𝐲)=∑k=1KP(xk)∏j=1JP(yj∣xk)=∑k=1KP(xk)exp(∑j=1Jlym∣xg). \\begin{aligned} P(\\mathbf{y}) \\;&=\\; \\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k) \\\\ &=\\; \\sum_{k=1}^{K} P(x_k)\\, \\exp\\bigg(\\sum_{j=1}^{J} l_{y_m \\mid x_g}\\bigg). \\end{aligned}  ∂ℓℓ∂P(xg)=n1P(𝐲)∏j=1JP(yj∣xg). \\frac{\\partial \\ell\\ell}{\\partial P(x_g)} \\;=\\; n \\,\\frac{1}{P(\\mathbf{y})}\\, \\prod_{j=1}^{J} P(y_j \\mid x_g).  specific item mm class gg, ∂ℓℓ∂lym∣xg=n1P(𝐲)P(xg)∏j=1JP(yj∣xg). \\frac{\\partial \\ell\\ell}{\\partial l_{y_m \\mid x_g}} \\;=\\; n \\,\\frac{1}{P(\\mathbf{y})}\\, P(x_g)\\, \\prod_{j=1}^{J} P(y_j \\mid x_g). Notice last expression just posterior, P(xg∣ym)P(x_g \\mid y_m), weighted nn.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class Model","text":"classes g,hg,h, ∂2ℓℓ∂P(xg)∂P(xh)=−n1P(𝐲)2(∏j=1JP(yj∣xg))(∏j=1JP(yj∣xh))=−nP(xg∣y)P(xh∣y)P(xg)P(xh). \\begin{aligned} \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_g)\\,\\partial P(x_h)} \\;&=\\; -\\,n \\,\\frac{1}{P(\\mathbf{y})^{2}} \\, \\Bigg(\\prod_{j=1}^{J} P(y_j \\mid x_g)\\Bigg)\\! \\Bigg(\\prod_{j=1}^{J} P(y_j \\mid x_h)\\Bigg) \\\\ &=\\; -n \\frac{P(x_g \\mid y) P(x_h \\mid y)}{P(x_g) P(x_h)}. \\end{aligned} items m,nm,n classes g,hg,h, ∂2ℓℓ∂lym∣xg∂lyn∣xh={nP(xg∣y)(1−P(xg∣y)),g=h,−nP(xg∣y)P(xh∣y),otherwise. \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial l_{y_n \\mid x_h}} = \\begin{cases} \\,n \\, P(x_g \\mid y) \\!\\ \\big(1-P(x_g \\mid y)\\big), & \\text{} \\!\\ g=h,\\\\[1.25em] -\\,n \\, P(x_g \\mid y) \\!\\ P(x_h \\mid y), & \\text{otherwise.} \\end{cases} mixed second derivative, ∂2ℓℓ∂P(xh)∂lym∣xg={1P(xg)nP(xg∣y)(1−P(xg∣y)),g=h,−1P(xh)nP(xg∣y)P(xh∣y),otherwise. \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_h)\\,\\partial l_{y_m \\mid x_g}} = \\begin{cases} \\frac{1}{P(x_g)} \\, n \\, P(x_g \\mid y) \\big(1-P(x_g \\mid y)\\big), & \\text{} g=h,\\\\[1.0em] -\\, \\frac{1}{P(x_h)} \\, n \\, P(x_g \\mid y) P(x_h \\mid y), & \\text{otherwise.} \\end{cases} Collecting terms gives Hessian block form: Hess(ℓℓ)=[∂2ℓℓ∂P(xg)∂P(xh)∂2ℓℓ∂P(xh)∂lym∣xg∂2ℓℓ∂lym∣xg∂P(xh)∂2ℓℓ∂lym∣xg∂lym∣xg]. \\mathrm{Hess}(\\ell\\ell) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_g)\\,\\partial P(x_h)} & \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_h)\\,\\partial l_{y_m \\mid x_g}} \\\\[0.8em] \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial P(x_h)} & \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial l_{y_m \\mid x_g}} \\end{bmatrix}\\!.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"models-for-the-conditional-likelihoods","dir":"Articles","previous_headings":"","what":"Models for the conditional likelihoods","title":"The Latent Class Model","text":"conditional probabilities need parameterized likelihood. consider multinomial likelihood categorical items Gaussian likelihood continuous items. categorical items, let πmk∣g\\pi_{m_k \\mid g} probability scoring category kk item mm subject belongs class gg. P(ym∣xg)=πmk∣g, P(y_m \\mid x_g) \\;=\\; \\pi_{m_k \\mid g},  kk ym=ky_m = k. parameterization, ∂lym∣xg∂πnk∣h={1πnk∣h,ym=k,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\pi_{n_k \\mid h}} = \\begin{cases} \\frac{1}{\\pi_{n_k \\mid h}}, & \\text{} y_m = k,\\ m=n,\\ g=h,\\\\ 0, & \\text{otherwise.} \\end{cases}  ∂2lyj∣xi∂πmk∣g∂πnl∣h={−1πmj∣i2,yj=k=l,y=m=n,=g=h,0,otherwise. \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} = \\begin{cases} -\\frac{1}{\\pi_{m_j \\mid }^2}, & \\text{} y_j = k = l,\\ y=m=n,\\ =g=h,\\\\ 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lym∣xg)=𝐞∂2lyj∣xi∂πmk∣g∂πnl∣h𝐞⊤, \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\mathbf{e} \\; \\displaystyle \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} \\; \\mathbf{e}^\\top,  𝐞\\mathbf{e} vector zeroes 1 position corresponding parameter πyj∣\\pi_{y_j \\mid }. Notice conditional parameter lym∣xgl_{y_m \\mid x_g} Hessian matrix. continuous items, let φ\\varphi denote normal density. Let μm∣g\\mu_{m\\mid g} σm∣g\\sigma_{m\\mid g} mean standard deviation item mm class gg. P(ym∣xg)=φ(ym;μm∣g,σm∣g). P(y_m \\mid x_g) \\;=\\; \\varphi\\!\\big(y_m;\\, \\mu_{m\\mid g},\\, \\sigma_{m\\mid g}\\big). First derivatives: ∂lym∣xg∂μn∣h={ym−μm∣gσm∣g2,m=n,g=h,0,otherwise, \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\mu_{n\\mid h}} = \\begin{cases} \\dfrac{y_m - \\mu_{m\\mid g}}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} ∂lym∣xg∂σn∣h={(ym−μm∣g)2−σm∣g2σm∣g3,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{(y_m-\\mu_{m\\mid g})^{2}-\\sigma_{m\\mid g}^{2}}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Second-order derivatives: ∂2lym∣xg∂μm∣g∂μn∣h={−1σm∣g2,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\mu_{n\\mid h}} = \\begin{cases} -\\dfrac{1}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} ∂2lym∣xg∂σm∣g∂σn∣h={1σm∣g2−3(ym−μm∣g)2σm∣g4,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{1}{\\sigma_{m\\mid g}^{2}} - \\dfrac{3(y_m-\\mu_{m\\mid g})^{2}}{\\sigma_{m\\mid g}^{4}}, & \\text{} m=n,\\ g=h,\\\\[1.0em] 0, & \\text{otherwise,} \\end{cases} ∂2lym∣xg∂μm∣g∂σn∣h={−2(ym−μm∣g)σm∣g3,m=n,g=h,0,otherwise. \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} -\\dfrac{2(y_m-\\mu_{m\\mid g})}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lym∣xg)=[∂2lym∣xg∂μm∣g∂μn∣h∂2lym∣xg∂μm∣g∂σn∣h∂2lym∣xg∂σn∣h∂μm∣g∂2lym∣xg∂σm∣g∂σn∣h]. \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\mu_{n \\mid h}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\\\[0.6em] \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{n \\mid h}\\,\\partial \\mu_{m \\mid g}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\end{bmatrix}. Notice conditional parameter lym∣xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial","dir":"Articles","previous_headings":"","what":"Multinomial","title":"The Latent Class Model","text":"categorical items, let πmk∣g\\pi_{m_k \\mid g} probability scoring category kk item mm subject belongs class gg. P(ym∣xg)=πmk∣g, P(y_m \\mid x_g) \\;=\\; \\pi_{m_k \\mid g},  kk ym=ky_m = k. parameterization, ∂lym∣xg∂πnk∣h={1πnk∣h,ym=k,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\pi_{n_k \\mid h}} = \\begin{cases} \\frac{1}{\\pi_{n_k \\mid h}}, & \\text{} y_m = k,\\ m=n,\\ g=h,\\\\ 0, & \\text{otherwise.} \\end{cases}  ∂2lyj∣xi∂πmk∣g∂πnl∣h={−1πmj∣i2,yj=k=l,y=m=n,=g=h,0,otherwise. \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} = \\begin{cases} -\\frac{1}{\\pi_{m_j \\mid }^2}, & \\text{} y_j = k = l,\\ y=m=n,\\ =g=h,\\\\ 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lym∣xg)=𝐞∂2lyj∣xi∂πmk∣g∂πnl∣h𝐞⊤, \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\mathbf{e} \\; \\displaystyle \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} \\; \\mathbf{e}^\\top,  𝐞\\mathbf{e} vector zeroes 1 position corresponding parameter πyj∣\\pi_{y_j \\mid }. Notice conditional parameter lym∣xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"gaussian","dir":"Articles","previous_headings":"","what":"Gaussian","title":"The Latent Class Model","text":"continuous items, let φ\\varphi denote normal density. Let μm∣g\\mu_{m\\mid g} σm∣g\\sigma_{m\\mid g} mean standard deviation item mm class gg. P(ym∣xg)=φ(ym;μm∣g,σm∣g). P(y_m \\mid x_g) \\;=\\; \\varphi\\!\\big(y_m;\\, \\mu_{m\\mid g},\\, \\sigma_{m\\mid g}\\big). First derivatives: ∂lym∣xg∂μn∣h={ym−μm∣gσm∣g2,m=n,g=h,0,otherwise, \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\mu_{n\\mid h}} = \\begin{cases} \\dfrac{y_m - \\mu_{m\\mid g}}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} ∂lym∣xg∂σn∣h={(ym−μm∣g)2−σm∣g2σm∣g3,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{(y_m-\\mu_{m\\mid g})^{2}-\\sigma_{m\\mid g}^{2}}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Second-order derivatives: ∂2lym∣xg∂μm∣g∂μn∣h={−1σm∣g2,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\mu_{n\\mid h}} = \\begin{cases} -\\dfrac{1}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} ∂2lym∣xg∂σm∣g∂σn∣h={1σm∣g2−3(ym−μm∣g)2σm∣g4,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{1}{\\sigma_{m\\mid g}^{2}} - \\dfrac{3(y_m-\\mu_{m\\mid g})^{2}}{\\sigma_{m\\mid g}^{4}}, & \\text{} m=n,\\ g=h,\\\\[1.0em] 0, & \\text{otherwise,} \\end{cases} ∂2lym∣xg∂μm∣g∂σn∣h={−2(ym−μm∣g)σm∣g3,m=n,g=h,0,otherwise. \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} -\\dfrac{2(y_m-\\mu_{m\\mid g})}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lym∣xg)=[∂2lym∣xg∂μm∣g∂μn∣h∂2lym∣xg∂μm∣g∂σn∣h∂2lym∣xg∂σn∣h∂μm∣g∂2lym∣xg∂σm∣g∂σn∣h]. \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\mu_{n \\mid h}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\\\[0.6em] \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{n \\mid h}\\,\\partial \\mu_{m \\mid g}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\end{bmatrix}. Notice conditional parameter lym∣xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-latent-class-probabilities","dir":"Articles","previous_headings":"","what":"Model for the latent class probabilities","title":"The Latent Class Model","text":"Probabilities class membership parameterized softmax transformation: P(xg)=exp(θg)∑jexp(θj), P(x_g) = \\frac{\\exp(\\theta_g)}{\\sum_j \\exp(\\theta_j)},  θg\\theta_g log-scale parameter associated class gg. jacobian transformation given J=diag(P)−PP⊤. J = \\mathrm{diag}(P) - PP^\\top.  Finally, Hessian probability Hess(P(xg))=P(xg)((eg−P)(eg−P)⊤−J), \\mathrm{Hess}\\big(P(x_g)\\big) \\;=\\; P(x_g)\\bigg((e_g−P)(e_g−P)^\\top−J\\bigg),  ege_g vector zeroes 11 position gg.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-conditional-probabilities-of-the-multinomial-model","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities of the multinomial model","title":"The Latent Class Model","text":"Probabilities conditional responses parameterized softmax transformation: πmk∣g=exp(ηmk∣g)∑jexp(ηmj∣g), \\pi_{m_k \\mid g} = \\frac{\\exp(\\eta_{m_k \\mid g})}{\\sum_j \\exp(\\eta_{m_j \\mid g})},  ηmk∣g\\eta_{m_k \\mid g} log-scale parameter associated response kk item mm class gg. jacobian transformation given Jm∣g=diag(πm∣g)−πm∣g(πm∣g)⊤. J_{m \\mid g} = \\mathrm{diag}(\\pi_{m \\mid g}) - \\pi_{m \\mid g} (\\pi_{m \\mid g})^\\top.  Finally, Hessian probability Hess(πmk∣g)=πm∣g((ek−πm∣g)(ek−πm∣g)⊤−J), \\mathrm{Hess}\\big( \\pi_{m_k \\mid g} \\big) \\;=\\; \\pi_{m \\mid g}\\bigg((e_k−\\pi_{m \\mid g})(e_k−\\pi_{m \\mid g})^\\top−J\\bigg),  eke_k vector zeroes 11 position kk.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"constant-priors","dir":"Articles","previous_headings":"","what":"Constant priors","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: λ2=∑m∑kπ̂mk∑gαKlog(πmk∣g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), π̂mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives ∂λ2∂πmk∣g=∑m∑kπ̂mk∑gαK1πmk∣g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives ∂2λ2∂πmk∣g∂πmk∣g=−∑m∑kπ̂mk∑gαK1πmk∣g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}. conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: λ3=∑gK(−0.5αKlog(∏jσj∣g2)−0.5αK∑jσ̂j2σj∣g2)=∑gK(−αK∑jsj∣g−0.5αK∑jσ̂j2σj∣g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} σ̂j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives ∂λ3∂σm∣g=∑gK−αKσm∣g+αKσm∣g3σ̂m∣g2=∑gKαK(σ̂m∣g2σm∣g3−1σm∣g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives ∂2λ3∂σm∣g∂σm∣g=∑gKαK(1σm∣g−3σ̂m∣g2σm∣g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"for-conditional-likelihoods","dir":"Articles","previous_headings":"","what":"For conditional likelihoods","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: λ2=∑m∑kπ̂mk∑gαKlog(πmk∣g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), π̂mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives ∂λ2∂πmk∣g=∑m∑kπ̂mk∑gαK1πmk∣g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives ∂2λ2∂πmk∣g∂πmk∣g=−∑m∑kπ̂mk∑gαK1πmk∣g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}. conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: λ3=∑gK(−0.5αKlog(∏jσj∣g2)−0.5αK∑jσ̂j2σj∣g2)=∑gK(−αK∑jsj∣g−0.5αK∑jσ̂j2σj∣g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} σ̂j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives ∂λ3∂σm∣g=∑gK−αKσm∣g+αKσm∣g3σ̂m∣g2=∑gKαK(σ̂m∣g2σm∣g3−1σm∣g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives ∂2λ3∂σm∣g∂σm∣g=∑gKαK(1σm∣g−3σ̂m∣g2σm∣g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial-1","dir":"Articles","previous_headings":"","what":"Multinomial","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: λ2=∑m∑kπ̂mk∑gαKlog(πmk∣g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), π̂mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives ∂λ2∂πmk∣g=∑m∑kπ̂mk∑gαK1πmk∣g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives ∂2λ2∂πmk∣g∂πmk∣g=−∑m∑kπ̂mk∑gαK1πmk∣g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"gaussian-1","dir":"Articles","previous_headings":"","what":"Gaussian","title":"The Latent Class Model","text":"conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: λ3=∑gK(−0.5αKlog(∏jσj∣g2)−0.5αK∑jσ̂j2σj∣g2)=∑gK(−αK∑jsj∣g−0.5αK∑jσ̂j2σj∣g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} σ̂j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives ∂λ3∂σm∣g=∑gK−αKσm∣g+αKσm∣g3σ̂m∣g2=∑gKαK(σ̂m∣g2σm∣g3−1σm∣g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives ∂2λ3∂σm∣g∂σm∣g=∑gKαK(1σm∣g−3σ̂m∣g2σm∣g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items 𝐲\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern 𝐲\\boldsymbol{y}, observed nn times sample, can written l=P(𝐲)n=(∑k=1KP(xk)P(𝐲|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(𝐲|xk)=∏j=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(∑k=1KP(xk)∏j=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(∑k=1KP(xk)∏j=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk ∂ll∂P(xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)∏j=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk ∂ll∂P(ym|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk ∂2ll∂P(xg)∂P(xh)=−n∏j=1JP(yj|xh)∏j=1JP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} ∂ll∂P(ym|xg)P(ym|xg)=−nP(xg)∏j≠mP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(ym|xg)P(yn|xg)=n∑k=1KP(xk)∏j=1JP(yj|xk)P(xg)∏j≠m,nP(yj|xg)−nP(xg)∏j≠nP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh ∂ll∂P(ym|xg)P(yn|xh)=−nP(xh)∏j≠nP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh ∂ll∂P(xg)∂P(ym|xg)=n∏j≠mP(yj|xg)∑k=1KP(xk)∏j=1JP(yj|xk)−n∏j=1JP(yj|xg)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. ∂ll∂P(xh)∂P(ym|xg)=−n∏j=1JP(yj|xh)P(xg)∏j≠mP(yj|xg)(∑k=1KP(xk)∏j=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. ∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=θjyj(1−θj)1−yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  θj\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect θj\\theta_j ∂P(yj|xk)θj=12yj−1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"∂P(ym|xg)∂θmk|g=nlP(xg)∏j≠mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcos Jiménez. Maintainer. Mauricio Garnier-Villarreal. . Vithor R. Franco. .","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jiménez M, Garnier-Villarreal M, Franco VR (2025). latent: R package Latent Variable Modeling. R package version 0.1.0, https://github.com/Marcosjnez/latent.","code":"@Manual{,   title = {latent: An R package for Latent Variable Modeling},   author = {Marcos Jiménez and Mauricio Garnier-Villarreal and Vithor R. Franco},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/Marcosjnez/latent}, }"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"latent-latent-class-and-factor-analysis-models","dir":"","previous_headings":"","what":"An R package for Latent Class and Factor Analysis Models","title":"An R package for Latent Class and Factor Analysis Models","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-windows-and-linux","dir":"","previous_headings":"","what":"Installation in Windows and Linux","title":"An R package for Latent Class and Factor Analysis Models","text":"","code":"devtools::install_github(\"marcosjnez/latent\", force = TRUE)"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Class and Factor Analysis Models","text":"Install macrtools R package James Balamuta: Install Command Line Tools R Compilation Toolchain (take minutes): Get OpenMP support: difficulties installation, check following resources: https://mac.thecoatlessprofessor.com/macrtools/index.html https://mac.thecoatlessprofessor.com/macrtools/reference/openmp.html Finally,","code":"# install.packages(\"remotes\") remotes::install_github(\"coatless-mac/macrtools\") macrtools::macos_rtools_install() macrtools::openmp_install() devtools::install_github(\"marcosjnez/latent\", force = TRUE)"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"An R package for Latent Class and Factor Analysis Models","text":"package development supported “DYNANSE: Righting Wrongs. Life Course Dynamics Approach Non-Standard Employment” project, received funding European Research Council (ERC) European Union’s Horizon 2020 research innovation programme (grant agreement 864471).","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: HolzingerSwineford1939 — HolzingerSwineford1939","title":"Example dataset: HolzingerSwineford1939 — HolzingerSwineford1939","text":"dataset lavaan R package.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: HolzingerSwineford1939 — HolzingerSwineford1939","text":"","code":"HolzingerSwineford1939"},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: HolzingerSwineford1939 — HolzingerSwineford1939","text":"data frame 301 rows 15 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: HolzingerSwineford1939 — HolzingerSwineford1939","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: cancer — cancer","title":"Example dataset: cancer — cancer","text":"dataset 475 rows 13 columns.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: cancer — cancer","text":"","code":"cancer"},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: cancer — cancer","text":"data frame 475 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: cancer — cancer","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. — cfast","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. — cfast","text":"Fit Confirmatory Factor Analysis (CFA) model lavaan syntax.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. — cfast","text":"","code":"cfast(data, model = NULL, cor = \"pearson\", estimator = \"ml\", group = NULL, sample.cov = NULL, nobs = NULL, missing = \"pairwise.complete.obs\", W = NULL, std.lv = FALSE, positive = FALSE, do.fit = TRUE, control = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. — cfast","text":"","code":"if (FALSE) { # \\dontrun{ # The famous Holzinger and Swineford (1939) example HS.model <- ' visual  =~ x1 + x2 + x3               textual =~ x4 + x5 + x6               speed   =~ x7 + x8 + x9 '  fit <- cfast(model = HS.model, data = HolzingerSwineford1939) summary(fit, digits = 3L) } # }"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: empathy — empathy","title":"Example dataset: empathy — empathy","text":"dataset tidySEM R package 467 rows 13 columns. first 6 columns continuous item responses.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: empathy — empathy","text":"","code":"empathy"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: empathy — empathy","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: empathy — empathy","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted values for Latent Class Analysis. — fitted.llca","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"Get fitted class membership probabilities latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"","code":"fitted(model)"},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"model Fitted llca object.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"Stuff: dof Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitted values for Latent Class Analysis. — fitted.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices — getfit.lcfa","title":"Fit indices — getfit.lcfa","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices — getfit.lcfa","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices — getfit.lcfa","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices — getfit.lcfa","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices — getfit.lcfa","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices — getfit.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices — getfit.llca","title":"Fit indices — getfit.llca","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices — getfit.llca","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices — getfit.llca","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices — getfit.llca","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices — getfit.llca","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices — getfit.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: gss82 — gss82","title":"Example dataset: gss82 — gss82","text":"dataset poLCA R package 1202 rows 4 columns. Items dichotomous polytomous.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: gss82 — gss82","text":"","code":"gss82"},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: gss82 — gss82","text":"data frame 1202 rows 4 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: gss82 — gss82","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — latInspect.lcfa","title":"Standard Errors — latInspect.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — latInspect.lcfa","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — latInspect.lcfa","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — latInspect.lcfa","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors — latInspect.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors — latInspect.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — latInspect.llca","title":"Standard Errors — latInspect.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — latInspect.llca","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — latInspect.llca","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — latInspect.llca","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors — latInspect.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors — latInspect.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":null,"dir":"Reference","previous_headings":"","what":"An R package for Latent Variable Modeling — latent-package","title":"An R package for Latent Variable Modeling — latent-package","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An R package for Latent Variable Modeling — latent-package","text":"DESCRIPTION file: package yet installed build time.   Index:  package yet installed build time.  ~~ overview use package, including important functions ~~","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An R package for Latent Variable Modeling — latent-package","text":"Marcos Jiménez [fnd, cre],   Mauricio Garnier-Villarreal [cre],   Vithor R. Franco [cre] Maintainer: Marcos Jiménez <m.j.jimenezhenriquez@vu.nl>, Mauricio Garnier-Villarreal <m.garniervillarreal@vu.nl>, Vithor R. Franco <vithorfranco@gmail.com>","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An R package for Latent Variable Modeling — latent-package","text":"~~ Literature references background information ~~","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An R package for Latent Variable Modeling — latent-package","text":"","code":"# simple examples of the most important functions"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. — lca","title":"Latent Class Analysis. — lca","text":"Estimate latent class models gaussian multinomial item models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. — lca","text":"","code":"lca(data, item = rep(\"gaussian\", ncol(data)), X = NULL, nclasses = 2L,     model = NULL, do.fit = TRUE, control = NULL, verbose = TRUE)"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. — lca","text":"data data frame matrix. nclasses Number latent classes. item Character vector model item (.e., \"gaussian\" \"multinomial\"). Defaults \"gaussian\" items. X Matrix covariates. penalties list penalty terms parameters. model List parameter labels. See 'details' information. .fit TRUE fit model FALSE return model setup. Defaults TRUE. control List control parameters optimization algorithm. See 'details' information.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. — lca","text":"List following objects: parameters model logarithm probabilities classes. f Logarithm likelihood maximum.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. — lca","text":"lca estimates models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. — lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicted values for Latent Class Analysis. — predict.llca","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"Get predicted class membership probabilities latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"","code":"predict(model, new = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"model Fitted llca object. new Matrix data.frame new predictors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"Stuff: dof Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predicted values for Latent Class Analysis. — predict.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. — print.lca","title":"Latent Class Analysis. — print.lca","text":"Print information latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. — print.lca","text":"","code":"lca(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. — print.lca","text":"model Character vector model item.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. — print.lca","text":"Stuff: dof Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. — print.lca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. — print.lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — se.lcfa","title":"Standard Errors — se.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — se.lcfa","text":"","code":"se_cfa(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — se.lcfa","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — se.lcfa","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors — se.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors — se.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors — se.llca","title":"Standard Errors — se.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors — se.llca","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors — se.llca","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors — se.llca","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors — se.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors — se.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate factor structures with misspecification errors. — simfactor","title":"Simulate factor structures with misspecification errors. — simfactor","text":"Simulate factor bifactor structures crossloadings, correlated factors, .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate factor structures with misspecification errors. — simfactor","text":"","code":"simfactor(nfactors = 5, nitems = 6, loadings = \"medium\", crossloadings = 0, correlations = 0, estimator = \"minres\", fit = \"rmsr\", misfit = 0, error_method = \"cudeck\", efa = FALSE, ngenerals = 0, loadings_g = \"medium\", correlations_g = 0, pure = FALSE, lambda = NULL, Phi = NULL, Psi = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate factor structures with misspecification errors. — simfactor","text":"nfactors Number factors. nitems Number items per factor. loadings Loadings' magnitude factors: \"low\", \"medium\" \"high\". Defaults \"medium\". crossloadings Magnitude cross-loadings among group factors. Defaults 0. correlations_g Correlation among general factors. Defaults 0. correlations Correlation among factors. Defaults 0. estimator estimator used generate population error: \"minres\" \"ml\". fit Fit index control population error. misfit Misfit value generate population error. error_method Method used control population error: c(\"yuan\", \"cudeck\"). Defaults \"cudeck\". efa Reproduce error EFA CFA. Defaults FALSE (CFA). ngenerals Number general factors. loadings_g Loadings' magnitude general factors: \"low\", \"medium\" \"high\". Defaults \"medium\". pure Fix pure item general factor. Defaults FALSE. lambda Custom loading matrix. Phi NULL, factors correlated value given correlations. Phi Custom Phi matrix. lambda NULL, Phi conformable loading matrix specified arguments. Psi Custom Psi matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate factor structures with misspecification errors. — simfactor","text":"List following objects: lambda Population loading matrix. Phi Population factor correlation matrix. Psi Population covariance matrix errors. R Model correlation matrix. R_error Model correlation matrix misspecification errors. uniquenesses Population uniquenesses. delta Minimum loss function correspond misfit value.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate factor structures with misspecification errors. — simfactor","text":"simfactor generates bi-factor generalized bifactor patterns cross-loadings, pure items correlations among general group factors. crossloading different 0, one cross-loading introduced item pertaining group factor. pure TRUE, one item loading group factor removed item loads entirely general factor. maintain item communalities constant upon modifications, item loading factors may shrunk (adding cross-loadings) increase (setting pure items). Loading magnitudes may range 0.3-0.5 (\"low\"), 0.4-0.6 (\"medium\") 0.5-0.7 (\"high\"). Custom ranges can supplied vectors (.e., c(0.2, 0.5))","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate factor structures with misspecification errors. — simfactor","text":"Cudeck, R., & Browne, M. W. (1992). Constructing covariance matrix yields specified minimizer specified minimum discrepancy function value. Psychometrika, 57(3), 357–369. doi:10.1007/BF02295424 Jiménez, M., Abad, F. J., Garcia-Garzon, E., & Garrido, L. E. (2023). Exploratory Bi-factor Analysis Multiple General Factors. Multivariate Behavioral Research, 58(6), 1072–1089. doi:10.1080/00273171.2023.2189571 Jiménez, M., Abad, F. J., Garcia-Garzon, E., Golino, H., Christensen, . P., & Garrido, L. E. (2023). Dimensionality assessment bifactor structures multiple general factors: network psychometrics approach. Psychological Methods. Advance online publication. doi:10.1037/met0000590 Yuan, K.-H., & Hayashi, K. (2003). Bootstrap approach inference power analysis based three test statistics covariance structure models. British Journal Mathematical Statistical Psychology, 56(1), 93–110. doi:10.1348/000711003321645368","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate factor structures with misspecification errors. — simfactor","text":"","code":"# Simulate data: sim <- simfactor(nfactors = 3, nitems = 4, correlations = 0.40,                  crossloadings = 0.30) sim$lambda #>               S1        S2        S3 #> item1  0.4995555 0.0000000 0.3000000 #> item2  0.4579534 0.0000000 0.0000000 #> item3  0.5465764 0.0000000 0.0000000 #> item4  0.5545043 0.0000000 0.0000000 #> item5  0.3000000 0.5749201 0.0000000 #> item6  0.0000000 0.4349881 0.0000000 #> item7  0.0000000 0.4068483 0.0000000 #> item8  0.0000000 0.4640771 0.0000000 #> item9  0.0000000 0.3000000 0.4804656 #> item10 0.0000000 0.0000000 0.4391340 #> item11 0.0000000 0.0000000 0.4807076 #> item12 0.0000000 0.0000000 0.4127323 sim$Phi #>      [,1] [,2] [,3] #> [1,]  1.0  0.4  0.4 #> [2,]  0.4  1.0  0.4 #> [3,]  0.4  0.4  1.0 scores <- MASS::mvrnorm(1e3, rep(0, nrow(sim$R_error)), Sigma = sim$R_error) s <- cor(scores)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices — summary.lcfa","title":"Fit indices — summary.lcfa","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices — summary.lcfa","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices — summary.lcfa","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices — summary.lcfa","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices — summary.lcfa","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices — summary.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices — summary.llca","title":"Fit indices — summary.llca","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices — summary.llca","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices — summary.llca","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices — summary.llca","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices — summary.llca","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices — summary.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: values — values","title":"Example dataset: values — values","text":"dataset poLCA R package 216 rows 4 columns. 4 columns dichotomous items.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: values — values","text":"","code":"values"},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: values — values","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: values — values","text":"Generated example","code":""}]
