[{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items ð²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ð²\\boldsymbol{y}, observed nn times sample, can written l=P(ð²)n=(âˆ‘k=1KP(xk)P(ð²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ð²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcos JimÃ©nez. Maintainer.","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"JimÃ©nez M, Garnier-Villarreal M, Franco VR, Abad FJ, Garcia-Garzon E, Garrido LE (2025). latent: R package Latent Variable Modeling. R package version 0.1.0, https://marcosjnez.github.io/latent/, https://github.com/Marcosjnez/latent.","code":"@Manual{,   title = {latent: An R package for Latent Variable Modeling},   author = {Marcos JimÃ©nez and Mauricio Garnier-Villarreal and Vithor R. Franco and Francisco J. Abad and Eduardo Garcia-Garzon and Luis E. Garrido},   year = {2025},   note = {R package version 0.1.0, https://marcosjnez.github.io/latent/},   url = {https://github.com/Marcosjnez/latent}, }"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"latent-confirmatory-and-exploratory-factor-analysis-models","dir":"","previous_headings":"","what":"An R package for Latent Variable Modeling","title":"An R package for Latent Variable Modeling","text":"Fit measurement models.","code":""},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-linux-and-windows","dir":"","previous_headings":"","what":"Installation in Linux and Windows","title":"An R package for Latent Variable Modeling","text":"Using remotes package: Using devtools package:","code":"install.packages(\"remotes\") remotes::install_github(\"marcosjnez/latent\") install.packages(\"devtools\") devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Variable Modeling","text":"Delete clang4,6,7 binary prior version gfortran installed: Remove gfortran install receipts: Remove clang4 installer receipt: Remove Makevars file Renviron file: Install Homebrew terminal: Verify installation : Install xcode, installed: Install libomp, llvm gettext terminal: Download install gfortran https://github.com/fxcoudert/gfortran--macOS/releases macOS version. Create directory ~/.R/, exist: Create file named Makevars directory: Open Makevars file paste following lines : Makevars file can opened edited R console: Install Rcpp RcppArmadillo R console: Install latent:","code":"sudo rm -rf /usr/local/clang{4,6,7} sudo rm -rf /usr/local/gfortran sudo rm -rf /usr/local/bin/gfortran sudo rm /private/var/db/receipts/com.gnu.gfortran.bom sudo rm /private/var/db/receipts/com.gnu.gfortran.plist sudo rm /private/var/db/receipts/com.rbinaries.clang4.bom sudo rm /private/var/db/receipts/com.rbinaries.clang4.plist rm ~/.R/Makevars rm ~/.Renviron /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"                                 echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' >> ~/.zprofile eval \"$(/opt/homebrew/bin/brew shellenv)\" brew doctor xcode-select --install brew install libomp brew install gettext brew install llvm sudo mkdir ~/.R sudo touch ~/.R/Makevars LOC = /usr/local/gfortran/ CC=$(LOC)/bin/gcc -fopenmp CXX=$(LOC)/bin/g++ -fopenmp # -O3 should be faster than -O2 (default) level optimisation .. CFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe CXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipe LDFLAGS=-L/usr/local/opt/gettext/lib -L$(LOC)/lib -Wl,-rpath,$(LOC)/lib CPPFLAGS=-I/usr/local/opt/gettext/include -I$(LOC)/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include file.edit(\"~/.R/Makevars\") install.packages(c('Rcpp', 'RcppArmadillo')) devtools::install_github(\"marcosjnez/latent\")"},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirmatory factor analysis. â€” cfast","title":"Confirmatory factor analysis. â€” cfast","text":"Confirmatory factor analysis.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirmatory factor analysis. â€” cfast","text":"","code":"cfast(   data,   model = NULL,   lambda = NULL,   phi = NULL,   psi = NULL,   cor = \"pearson\",   estimator = \"uls\",   rotate = NULL,   missing = \"pairwise.complete.cases\",   nobs = NULL,   group = NULL,   invariance = \"none\",   control = NULL,   std.lv = FALSE,   positive = FALSE )"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” getfit","title":"Fit indices â€” getfit","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” getfit","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” getfit","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” getfit","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” getfit","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” getfit","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the default model for Latent Class Analysis. â€” getmodel","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"Get default model Latent Class Analysis.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"","code":"getmodel(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L)"},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"data data.frame matrix response. model Character vector model item. nclasses Number latent classes.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"List following objects: classes model probabilities classes. conditionals model conditional response probabilities.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"getmodel generates model probability belonging classes conditional response probabilities. models may modified user set equality constraints fix parameters.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get the default model for Latent Class Analysis. â€” getmodel","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":null,"dir":"Reference","previous_headings":"","what":"An R package for Latent Variable Modeling â€” latent-package","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Fit latent variable models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An R package for Latent Variable Modeling â€” latent-package","text":"DESCRIPTION file: package yet installed build time.   Index:  package yet installed build time.  ~~ overview use package, including important functions ~~","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Marcos JimÃ©nez [aut, cre],   Mauricio Garnier-Villarreal [aut],   Vithor R. Franco [aut],   Francisco J. Abad [aut],   Eduardo Garcia-Garzon [aut],   Luis E. Garrido [aut] Maintainer: Marcos JimÃ©nez <m.j.jimenezhenriquez@vu.nl>","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An R package for Latent Variable Modeling â€” latent-package","text":"~~ Literature references background information ~~","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An R package for Latent Variable Modeling â€” latent-package","text":"","code":"# simple examples of the most important functions"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. â€” lca","title":"Latent Class Analysis. â€” lca","text":"Estimate latent class models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. â€” lca","text":"","code":"lca(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. â€” lca","text":"data data.frame matrix response. nclasses Number latent classes. model Character vector model item. control List control parameters optimization algorithm. See 'details' information.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. â€” lca","text":"List following objects: parameters model probabilities classes. f Logarithm likelihood maximum.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. â€” lca","text":"lca estimates models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. â€” lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. â€” print.lca","title":"Latent Class Analysis. â€” print.lca","text":"Print information latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. â€” print.lca","text":"","code":"lca(data, model = rep(\"multinomial\", ncol(data)), nclasses = 2L, control = list(opt = \"lbfgs\", rstarts = 30L, cores = 1L))"},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. â€” print.lca","text":"model Character vector model item.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. â€” print.lca","text":"Stuff: df Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. â€” print.lca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/print.lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. â€” print.lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors â€” se","title":"Standard Errors â€” se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors â€” se","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors â€” se","text":"fit model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors â€” se","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors â€” se","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors â€” se","text":"None yet.","code":""}]
