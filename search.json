[{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class Model","text":"Latent Class Analysis assumes people belong different groups (.e., classes) due nonobservable characteristics. latent class model, aim estimate two kinds probabilities: probability person belongs particular class. conditional probabilities item responses person belongs given class.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class Model","text":"Suppose sample people respond JJ items ğ²\\mathbf{y} vector contains scores item jj. Let KK denote number latent classes let xkx_k class kk. , likelihood response pattern ğ²\\mathbf{y}, observed nn times sample every person responds independently , can written â„“=P(ğ²)n=(âˆ‘k=1KP(xk)P(ğ²âˆ£xk))n. \\ell \\;=\\; P(\\mathbf{y})^{n} \\;=\\; \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, P(\\mathbf{y}\\mid x_k)\\Bigg)^{n}. Assuming local independence (responses within person independent conditional class), P(ğ²âˆ£xk)=âˆj=1JP(yjâˆ£xk), P(\\mathbf{y}\\mid x_k) \\;=\\; \\prod_{j=1}^{J} P(y_j \\mid x_k),  yjy_j denotes score item jj. Hence, â„“=(âˆ‘k=1KP(xk)âˆj=1JP(yjâˆ£xk))n, \\ell \\;=\\; \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k)\\Bigg)^{\\!n},  log-likelihood becomes â„“â„“=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yjâˆ£xk)). \\ell\\ell \\;=\\; n \\log \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k)\\Bigg).  term inside parenthesis probability single pattern, P(ğ²)P(\\mathbf{y}). Assuming independence people different response patterns, log-likelihood whole sample sum log-likelihoods response pattern. simplify computation logarithm likelihood related derivatives, let lymâˆ£xg=logP(ymâˆ£xg)l_{y_m \\mid x_g} = \\log P(y_m \\mid x_g), â„“â„“=nlog(âˆ‘k=1KP(xk)exp(âˆ‘j=1Jlymâˆ£xg)). \\ell\\ell \\;=\\; n \\log \\Bigg(\\sum_{k=1}^{K} P(x_k)\\, \\exp\\bigg(\\sum_{j=1}^{J} l_{y_m \\mid x_g}\\bigg)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class Model","text":"fixed pattern ğ²\\mathbf{y}, define P(ğ²)=âˆ‘k=1KP(xk)âˆj=1JP(yjâˆ£xk)=âˆ‘k=1KP(xk)exp(âˆ‘j=1Jlymâˆ£xg). \\begin{aligned} P(\\mathbf{y}) \\;&=\\; \\sum_{k=1}^{K} P(x_k)\\, \\prod_{j=1}^{J} P(y_j \\mid x_k) \\\\ &=\\; \\sum_{k=1}^{K} P(x_k)\\, \\exp\\bigg(\\sum_{j=1}^{J} l_{y_m \\mid x_g}\\bigg). \\end{aligned}  âˆ‚â„“â„“âˆ‚P(xg)=n1P(ğ²)âˆj=1JP(yjâˆ£xg). \\frac{\\partial \\ell\\ell}{\\partial P(x_g)} \\;=\\; n \\,\\frac{1}{P(\\mathbf{y})}\\, \\prod_{j=1}^{J} P(y_j \\mid x_g).  specific item mm class gg, âˆ‚â„“â„“âˆ‚lymâˆ£xg=n1P(ğ²)P(xg)âˆj=1JP(yjâˆ£xg). \\frac{\\partial \\ell\\ell}{\\partial l_{y_m \\mid x_g}} \\;=\\; n \\,\\frac{1}{P(\\mathbf{y})}\\, P(x_g)\\, \\prod_{j=1}^{J} P(y_j \\mid x_g). Notice last expression just posterior, P(xgâˆ£ym)P(x_g \\mid y_m), weighted nn.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"directional-derivatives-of-first-order-derivatives","dir":"Articles","previous_headings":"","what":"Directional derivatives of first-order derivatives","title":"The Latent Class Model","text":"d[âˆ‚â„“â„“âˆ‚P(xg)]=nP(ğ²)d[âˆj=1JP(yjâˆ£xg)]âˆ’d[P(ğ²)]âˆj=1JP(yjâˆ£xg)P(ğ²)2, d \\Bigg[ \\frac{\\partial \\ell\\ell}{\\partial P(x_g)} \\Bigg] \\;=\\; n \\,\\frac{P(\\mathbf{y}) \\; d\\big[\\prod_{j=1}^{J} P(y_j \\mid x_g)\\big] - d\\big[P(\\mathbf{y})\\big] \\; \\prod_{j=1}^{J} P(y_j \\mid x_g)}{P(\\mathbf{y})^2},  d[âˆj=1JP(yjâˆ£xg)]=âˆj=1JP(yjâˆ£xg)P(yjâˆ£xg)d[P(yjâˆ£xg)], d\\big[\\prod_{j=1}^{J} P(y_j \\mid x_g)\\big] = \\frac{\\prod_{j=1}^{J} P(y_j \\mid x_g)}{P(y_j \\mid x_g) \\, d\\big[P(y_j \\mid x_g)\\big]},  d[P(ğ²)]=âˆ‘k=1Kd[P(xk)]âˆj=1JP(yjâˆ£xk)+âˆ‘k=1KP(xk)d[âˆj=1JP(yjâˆ£xk)]. d\\big[P(\\mathbf{y})\\big] = \\sum_{k=1}^{K} d\\big[P(x_k)] \\, \\prod_{j=1}^{J} P(y_j \\mid x_k) + \\sum_{k=1}^{K} P(x_k) \\, d\\big[\\prod_{j=1}^{J} P(y_j \\mid x_k)].","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class Model","text":"classes g,hg,h, âˆ‚2â„“â„“âˆ‚P(xg)âˆ‚P(xh)=âˆ’n1P(ğ²)2(âˆj=1JP(yjâˆ£xg))(âˆj=1JP(yjâˆ£xh))=âˆ’nP(xgâˆ£y)P(xhâˆ£y)P(xg)P(xh). \\begin{aligned} \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_g)\\,\\partial P(x_h)} \\;&=\\; -\\,n \\,\\frac{1}{P(\\mathbf{y})^{2}} \\, \\Bigg(\\prod_{j=1}^{J} P(y_j \\mid x_g)\\Bigg)\\! \\Bigg(\\prod_{j=1}^{J} P(y_j \\mid x_h)\\Bigg) \\\\ &=\\; -n \\frac{P(x_g \\mid y) P(x_h \\mid y)}{P(x_g) P(x_h)}. \\end{aligned} items m,nm,n classes g,hg,h, âˆ‚2â„“â„“âˆ‚lymâˆ£xgâˆ‚lynâˆ£xh={nP(xgâˆ£y)(1âˆ’P(xgâˆ£y)),g=h,âˆ’nP(xgâˆ£y)P(xhâˆ£y),otherwise. \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial l_{y_n \\mid x_h}} = \\begin{cases} \\,n \\, P(x_g \\mid y) \\!\\ \\big(1-P(x_g \\mid y)\\big), & \\text{} \\!\\ g=h,\\\\[1.25em] -\\,n \\, P(x_g \\mid y) \\!\\ P(x_h \\mid y), & \\text{otherwise.} \\end{cases} mixed second derivative, âˆ‚2â„“â„“âˆ‚P(xh)âˆ‚lymâˆ£xg={1P(xg)nP(xgâˆ£y)(1âˆ’P(xgâˆ£y)),g=h,âˆ’1P(xh)nP(xgâˆ£y)P(xhâˆ£y),otherwise. \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_h)\\,\\partial l_{y_m \\mid x_g}} = \\begin{cases} \\frac{1}{P(x_g)} \\, n \\, P(x_g \\mid y) \\big(1-P(x_g \\mid y)\\big), & \\text{} g=h,\\\\[1.0em] -\\, \\frac{1}{P(x_h)} \\, n \\, P(x_g \\mid y) P(x_h \\mid y), & \\text{otherwise.} \\end{cases} Collecting terms gives Hessian block form: Hess(â„“â„“)=[âˆ‚2â„“â„“âˆ‚P(xg)âˆ‚P(xh)âˆ‚2â„“â„“âˆ‚P(xh)âˆ‚lymâˆ£xgâˆ‚2â„“â„“âˆ‚lymâˆ£xgâˆ‚P(xh)âˆ‚2â„“â„“âˆ‚lymâˆ£xgâˆ‚lymâˆ£xg]. \\mathrm{Hess}(\\ell\\ell) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_g)\\,\\partial P(x_h)} & \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial P(x_h)\\,\\partial l_{y_m \\mid x_g}} \\\\[0.8em] \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial P(x_h)} & \\displaystyle \\frac{\\partial^2 \\ell\\ell}{\\partial l_{y_m \\mid x_g}\\,\\partial l_{y_m \\mid x_g}} \\end{bmatrix}\\!.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"models-for-the-conditional-likelihoods","dir":"Articles","previous_headings":"","what":"Models for the conditional likelihoods","title":"The Latent Class Model","text":"conditional probabilities need parameterized likelihood. consider multinomial likelihood categorical items Gaussian likelihood continuous items. categorical items, let Ï€mkâˆ£g\\pi_{m_k \\mid g} probability scoring category kk item mm subject belongs class gg. P(ymâˆ£xg)=Ï€mkâˆ£g, P(y_m \\mid x_g) \\;=\\; \\pi_{m_k \\mid g},  kk ym=ky_m = k. parameterization, âˆ‚lymâˆ£xgâˆ‚Ï€nkâˆ£h={1Ï€nkâˆ£h,ym=k,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\pi_{n_k \\mid h}} = \\begin{cases} \\frac{1}{\\pi_{n_k \\mid h}}, & \\text{} y_m = k,\\ m=n,\\ g=h,\\\\ 0, & \\text{otherwise.} \\end{cases}  âˆ‚2lyjâˆ£xiâˆ‚Ï€mkâˆ£gâˆ‚Ï€nlâˆ£h={âˆ’1Ï€mjâˆ£i2,yj=k=l,y=m=n,=g=h,0,otherwise. \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} = \\begin{cases} -\\frac{1}{\\pi_{m_j \\mid }^2}, & \\text{} y_j = k = l,\\ y=m=n,\\ =g=h,\\\\ 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lymâˆ£xg)=ğâˆ‚2lyjâˆ£xiâˆ‚Ï€mkâˆ£gâˆ‚Ï€nlâˆ£hğâŠ¤, \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\mathbf{e} \\; \\displaystyle \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} \\; \\mathbf{e}^\\top,  ğ\\mathbf{e} vector zeroes 1 position corresponding parameter Ï€yjâˆ£\\pi_{y_j \\mid }. Notice conditional parameter lymâˆ£xgl_{y_m \\mid x_g} Hessian matrix. continuous items, let Ï†\\varphi denote normal density. Let Î¼mâˆ£g\\mu_{m\\mid g} Ïƒmâˆ£g\\sigma_{m\\mid g} mean standard deviation item mm class gg. P(ymâˆ£xg)=Ï†(ym;Î¼mâˆ£g,Ïƒmâˆ£g). P(y_m \\mid x_g) \\;=\\; \\varphi\\!\\big(y_m;\\, \\mu_{m\\mid g},\\, \\sigma_{m\\mid g}\\big). First derivatives: âˆ‚lymâˆ£xgâˆ‚Î¼nâˆ£h={ymâˆ’Î¼mâˆ£gÏƒmâˆ£g2,m=n,g=h,0,otherwise, \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\mu_{n\\mid h}} = \\begin{cases} \\dfrac{y_m - \\mu_{m\\mid g}}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} âˆ‚lymâˆ£xgâˆ‚Ïƒnâˆ£h={(ymâˆ’Î¼mâˆ£g)2âˆ’Ïƒmâˆ£g2Ïƒmâˆ£g3,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{(y_m-\\mu_{m\\mid g})^{2}-\\sigma_{m\\mid g}^{2}}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Second-order derivatives: âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Î¼nâˆ£h={âˆ’1Ïƒmâˆ£g2,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\mu_{n\\mid h}} = \\begin{cases} -\\dfrac{1}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} âˆ‚2lymâˆ£xgâˆ‚Ïƒmâˆ£gâˆ‚Ïƒnâˆ£h={1Ïƒmâˆ£g2âˆ’3(ymâˆ’Î¼mâˆ£g)2Ïƒmâˆ£g4,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{1}{\\sigma_{m\\mid g}^{2}} - \\dfrac{3(y_m-\\mu_{m\\mid g})^{2}}{\\sigma_{m\\mid g}^{4}}, & \\text{} m=n,\\ g=h,\\\\[1.0em] 0, & \\text{otherwise,} \\end{cases} âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Ïƒnâˆ£h={âˆ’2(ymâˆ’Î¼mâˆ£g)Ïƒmâˆ£g3,m=n,g=h,0,otherwise. \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} -\\dfrac{2(y_m-\\mu_{m\\mid g})}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lymâˆ£xg)=[âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Î¼nâˆ£hâˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Ïƒnâˆ£hâˆ‚2lymâˆ£xgâˆ‚Ïƒnâˆ£hâˆ‚Î¼mâˆ£gâˆ‚2lymâˆ£xgâˆ‚Ïƒmâˆ£gâˆ‚Ïƒnâˆ£h]. \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\mu_{n \\mid h}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\\\[0.6em] \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{n \\mid h}\\,\\partial \\mu_{m \\mid g}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\end{bmatrix}. Notice conditional parameter lymâˆ£xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial","dir":"Articles","previous_headings":"","what":"Multinomial","title":"The Latent Class Model","text":"categorical items, let Ï€mkâˆ£g\\pi_{m_k \\mid g} probability scoring category kk item mm subject belongs class gg. P(ymâˆ£xg)=Ï€mkâˆ£g, P(y_m \\mid x_g) \\;=\\; \\pi_{m_k \\mid g},  kk ym=ky_m = k. parameterization, âˆ‚lymâˆ£xgâˆ‚Ï€nkâˆ£h={1Ï€nkâˆ£h,ym=k,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\pi_{n_k \\mid h}} = \\begin{cases} \\frac{1}{\\pi_{n_k \\mid h}}, & \\text{} y_m = k,\\ m=n,\\ g=h,\\\\ 0, & \\text{otherwise.} \\end{cases}  âˆ‚2lyjâˆ£xiâˆ‚Ï€mkâˆ£gâˆ‚Ï€nlâˆ£h={âˆ’1Ï€mjâˆ£i2,yj=k=l,y=m=n,=g=h,0,otherwise. \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} = \\begin{cases} -\\frac{1}{\\pi_{m_j \\mid }^2}, & \\text{} y_j = k = l,\\ y=m=n,\\ =g=h,\\\\ 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lymâˆ£xg)=ğâˆ‚2lyjâˆ£xiâˆ‚Ï€mkâˆ£gâˆ‚Ï€nlâˆ£hğâŠ¤, \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\mathbf{e} \\; \\displaystyle \\frac{\\partial^2 l_{y_j \\mid x_i}}{\\partial \\pi_{m_k \\mid g} \\partial \\pi_{n_l \\mid h}} \\; \\mathbf{e}^\\top,  ğ\\mathbf{e} vector zeroes 1 position corresponding parameter Ï€yjâˆ£\\pi_{y_j \\mid }. Notice conditional parameter lymâˆ£xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"gaussian","dir":"Articles","previous_headings":"","what":"Gaussian","title":"The Latent Class Model","text":"continuous items, let Ï†\\varphi denote normal density. Let Î¼mâˆ£g\\mu_{m\\mid g} Ïƒmâˆ£g\\sigma_{m\\mid g} mean standard deviation item mm class gg. P(ymâˆ£xg)=Ï†(ym;Î¼mâˆ£g,Ïƒmâˆ£g). P(y_m \\mid x_g) \\;=\\; \\varphi\\!\\big(y_m;\\, \\mu_{m\\mid g},\\, \\sigma_{m\\mid g}\\big). First derivatives: âˆ‚lymâˆ£xgâˆ‚Î¼nâˆ£h={ymâˆ’Î¼mâˆ£gÏƒmâˆ£g2,m=n,g=h,0,otherwise, \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\mu_{n\\mid h}} = \\begin{cases} \\dfrac{y_m - \\mu_{m\\mid g}}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} âˆ‚lymâˆ£xgâˆ‚Ïƒnâˆ£h={(ymâˆ’Î¼mâˆ£g)2âˆ’Ïƒmâˆ£g2Ïƒmâˆ£g3,m=n,g=h,0,otherwise. \\frac{\\partial l_{y_m \\mid x_g}}{\\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{(y_m-\\mu_{m\\mid g})^{2}-\\sigma_{m\\mid g}^{2}}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Second-order derivatives: âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Î¼nâˆ£h={âˆ’1Ïƒmâˆ£g2,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\mu_{n\\mid h}} = \\begin{cases} -\\dfrac{1}{\\sigma_{m\\mid g}^{2}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise,} \\end{cases} âˆ‚2lymâˆ£xgâˆ‚Ïƒmâˆ£gâˆ‚Ïƒnâˆ£h={1Ïƒmâˆ£g2âˆ’3(ymâˆ’Î¼mâˆ£g)2Ïƒmâˆ£g4,m=n,g=h,0,otherwise, \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} \\dfrac{1}{\\sigma_{m\\mid g}^{2}} - \\dfrac{3(y_m-\\mu_{m\\mid g})^{2}}{\\sigma_{m\\mid g}^{4}}, & \\text{} m=n,\\ g=h,\\\\[1.0em] 0, & \\text{otherwise,} \\end{cases} âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Ïƒnâˆ£h={âˆ’2(ymâˆ’Î¼mâˆ£g)Ïƒmâˆ£g3,m=n,g=h,0,otherwise. \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m\\mid g}\\, \\partial \\sigma_{n\\mid h}} = \\begin{cases} -\\dfrac{2(y_m-\\mu_{m\\mid g})}{\\sigma_{m\\mid g}^{3}}, & \\text{} m=n,\\ g=h,\\\\[0.6em] 0, & \\text{otherwise.} \\end{cases} Consequently, Hessian conditional parameter following block form: Hess(lymâˆ£xg)=[âˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Î¼nâˆ£hâˆ‚2lymâˆ£xgâˆ‚Î¼mâˆ£gâˆ‚Ïƒnâˆ£hâˆ‚2lymâˆ£xgâˆ‚Ïƒnâˆ£hâˆ‚Î¼mâˆ£gâˆ‚2lymâˆ£xgâˆ‚Ïƒmâˆ£gâˆ‚Ïƒnâˆ£h]. \\mathrm{Hess}(l_{y_m \\mid x_g}) \\;=\\; \\begin{bmatrix} \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\mu_{n \\mid h}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\mu_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\\\[0.6em] \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{n \\mid h}\\,\\partial \\mu_{m \\mid g}} & \\displaystyle \\frac{\\partial^{2} l_{y_m \\mid x_g}}{\\partial \\sigma_{m \\mid g}\\,\\partial \\sigma_{n \\mid h}} \\end{bmatrix}. Notice conditional parameter lymâˆ£xgl_{y_m \\mid x_g} Hessian matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-latent-class-probabilities","dir":"Articles","previous_headings":"","what":"Model for the latent class probabilities","title":"The Latent Class Model","text":"Probabilities class membership parameterized softmax transformation: P(xg)=exp(Î¸g)âˆ‘jexp(Î¸j), P(x_g) = \\frac{\\exp(\\theta_g)}{\\sum_j \\exp(\\theta_j)},  Î¸g\\theta_g log-scale parameter associated class gg. jacobian transformation given J=diag(P)âˆ’PPâŠ¤. J = \\mathrm{diag}(P) - PP^\\top.  Finally, Hessian probability Hess(P(xg))=P(xg)((egâˆ’P)(egâˆ’P)âŠ¤âˆ’J), \\mathrm{Hess}\\big(P(x_g)\\big) \\;=\\; P(x_g)\\bigg((e_gâˆ’P)(e_gâˆ’P)^\\topâˆ’J\\bigg),  ege_g vector zeroes 11 position gg.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"model-for-the-conditional-probabilities-of-the-multinomial-model","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities of the multinomial model","title":"The Latent Class Model","text":"Probabilities conditional responses parameterized softmax transformation: Ï€mkâˆ£g=exp(Î·mkâˆ£g)âˆ‘jexp(Î·mjâˆ£g), \\pi_{m_k \\mid g} = \\frac{\\exp(\\eta_{m_k \\mid g})}{\\sum_j \\exp(\\eta_{m_j \\mid g})},  Î·mkâˆ£g\\eta_{m_k \\mid g} log-scale parameter associated response kk item mm class gg. jacobian transformation given Jmâˆ£g=diag(Ï€mâˆ£g)âˆ’Ï€mâˆ£g(Ï€mâˆ£g)âŠ¤. J_{m \\mid g} = \\mathrm{diag}(\\pi_{m \\mid g}) - \\pi_{m \\mid g} (\\pi_{m \\mid g})^\\top.  Finally, Hessian probability Hess(Ï€mkâˆ£g)=Ï€mâˆ£g((ekâˆ’Ï€mâˆ£g)(ekâˆ’Ï€mâˆ£g)âŠ¤âˆ’J), \\mathrm{Hess}\\big( \\pi_{m_k \\mid g} \\big) \\;=\\; \\pi_{m \\mid g}\\bigg((e_kâˆ’\\pi_{m \\mid g})(e_kâˆ’\\pi_{m \\mid g})^\\topâˆ’J\\bigg),  eke_k vector zeroes 11 position kk.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"constant-priors","dir":"Articles","previous_headings":"","what":"Constant priors","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: Î»2=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±Klog(Ï€mkâˆ£g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), Ï€Ì‚mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives âˆ‚Î»2âˆ‚Ï€mkâˆ£g=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives âˆ‚2Î»2âˆ‚Ï€mkâˆ£gâˆ‚Ï€mkâˆ£g=âˆ’âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}. conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: Î»3=âˆ‘gK(âˆ’0.5Î±Klog(âˆjÏƒjâˆ£g2)âˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2)=âˆ‘gK(âˆ’Î±Kâˆ‘jsjâˆ£gâˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} ÏƒÌ‚j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives âˆ‚Î»3âˆ‚Ïƒmâˆ£g=âˆ‘gKâˆ’Î±KÏƒmâˆ£g+Î±KÏƒmâˆ£g3ÏƒÌ‚mâˆ£g2=âˆ‘gKÎ±K(ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g3âˆ’1Ïƒmâˆ£g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives âˆ‚2Î»3âˆ‚Ïƒmâˆ£gâˆ‚Ïƒmâˆ£g=âˆ‘gKÎ±K(1Ïƒmâˆ£gâˆ’3ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"for-conditional-likelihoods","dir":"Articles","previous_headings":"","what":"For conditional likelihoods","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: Î»2=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±Klog(Ï€mkâˆ£g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), Ï€Ì‚mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives âˆ‚Î»2âˆ‚Ï€mkâˆ£g=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives âˆ‚2Î»2âˆ‚Ï€mkâˆ£gâˆ‚Ï€mkâˆ£g=âˆ’âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}. conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: Î»3=âˆ‘gK(âˆ’0.5Î±Klog(âˆjÏƒjâˆ£g2)âˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2)=âˆ‘gK(âˆ’Î±Kâˆ‘jsjâˆ£gâˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} ÏƒÌ‚j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives âˆ‚Î»3âˆ‚Ïƒmâˆ£g=âˆ‘gKâˆ’Î±KÏƒmâˆ£g+Î±KÏƒmâˆ£g3ÏƒÌ‚mâˆ£g2=âˆ‘gKÎ±K(ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g3âˆ’1Ïƒmâˆ£g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives âˆ‚2Î»3âˆ‚Ïƒmâˆ£gâˆ‚Ïƒmâˆ£g=âˆ‘gKÎ±K(1Ïƒmâˆ£gâˆ’3ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"multinomial-1","dir":"Articles","previous_headings":"","what":"Multinomial","title":"The Latent Class Model","text":"conditional probabilities modeled multinomial likelihood, add following term log-likelihood class gg: Î»2=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±Klog(Ï€mkâˆ£g), \\lambda_2 = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\log (\\pi_{m_k \\mid g}), Ï€Ì‚mk\\hat{\\pi}_{m_k} proportion times category kk selected item mm. first-order derivatives âˆ‚Î»2âˆ‚Ï€mkâˆ£g=âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g. \\frac{\\partial \\lambda_2}{\\partial \\pi_{m_k \\mid g}} = \\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi_{m_k \\mid g}}. second-order derivatives âˆ‚2Î»2âˆ‚Ï€mkâˆ£gâˆ‚Ï€mkâˆ£g=âˆ’âˆ‘mâˆ‘kÏ€Ì‚mkâˆ‘gÎ±K1Ï€mkâˆ£g2. \\frac{\\partial^2 \\lambda_2}{\\partial \\pi_{m_k \\mid g} \\; \\partial \\pi_{m_k \\mid g}} = -\\sum_m \\sum_k \\hat{\\pi}_{m_k} \\sum_g \\frac{\\alpha}{K} \\frac{1}{\\pi^2_{m_k \\mid g}}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_article.html","id":"gaussian-1","dir":"Articles","previous_headings":"","what":"Gaussian","title":"The Latent Class Model","text":"conditional probabilities modeled gaussian likelihood, add following term log-likelihood class gg: Î»3=âˆ‘gK(âˆ’0.5Î±Klog(âˆjÏƒjâˆ£g2)âˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2)=âˆ‘gK(âˆ’Î±Kâˆ‘jsjâˆ£gâˆ’0.5Î±Kâˆ‘jÏƒÌ‚j2Ïƒjâˆ£g2), \\begin{aligned} \\lambda_3 &= \\sum_g^K \\left( -0.5\\frac{\\alpha}{K} \\log\\bigg(\\prod_j \\sigma^2_{j\\mid g}\\bigg) - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right) \\\\ &= \\sum_g^K \\left( -\\frac{\\alpha}{K} \\sum_j s_{j\\mid g} - 0.5\\frac{\\alpha}{K} \\sum_j \\frac{\\hat{\\sigma}^2_j}{\\sigma^2_{j \\mid g}} \\right), \\end{aligned} ÏƒÌ‚j2\\hat{\\sigma}^2_j variance item jj. first-order derivatives âˆ‚Î»3âˆ‚Ïƒmâˆ£g=âˆ‘gKâˆ’Î±KÏƒmâˆ£g+Î±KÏƒmâˆ£g3ÏƒÌ‚mâˆ£g2=âˆ‘gKÎ±K(ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g3âˆ’1Ïƒmâˆ£g). \\begin{aligned} \\frac{\\partial \\lambda_3}{\\partial \\sigma_{m \\mid g}} \\;&=\\; \\sum_g^K -\\frac{\\alpha}{K \\sigma_{m \\mid g}} + \\frac{\\alpha}{K \\sigma^3_{m \\mid g}} \\hat{\\sigma}^2_{m \\mid g}\\\\ &= \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^3_{m \\mid g}} - \\frac{1}{\\sigma_{m \\mid g}}\\Bigg). \\end{aligned} second-order derivatives âˆ‚2Î»3âˆ‚Ïƒmâˆ£gâˆ‚Ïƒmâˆ£g=âˆ‘gKÎ±K(1Ïƒmâˆ£gâˆ’3ÏƒÌ‚mâˆ£g2Ïƒmâˆ£g4). \\frac{\\partial^2 \\lambda_3}{\\partial \\sigma_{m \\mid g} \\partial \\sigma_{m \\mid g}} \\;=\\; \\sum_g^K \\frac{\\alpha}{K} \\Bigg(\\frac{1}{\\sigma_{m \\mid g}} - 3\\frac{\\hat{\\sigma}^2_{m \\mid g}}{\\sigma^4_{m \\mid g}}\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"latent-class-analysis","dir":"Articles","previous_headings":"","what":"Latent Class Analysis","title":"The Latent Class model","text":"Sometimes, people belong different groups (.e., classes) due nonobservable characteristics. fact conditions probability selecting particular response option answering item. Latent Class Analysis statistical model estimates probability person belongs particular class conditional probabilities selecting particular response option conditioning given class. Suppose sample people respond JJ items ğ²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ğ²\\boldsymbol{y}, observed nn times sample, can written l=P(ğ²)n=(âˆ‘k=1KP(xk)P(ğ²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ğ²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg). partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g). softmax trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"the-likelihood","dir":"Articles","previous_headings":"","what":"The likelihood","title":"The Latent Class model","text":"Suppose sample people respond JJ items ğ²\\boldsymbol{y} vector contains scores item jj. Also, let KK denote number latent classes xkx_k, specific class kk. , likelihood response pattern ğ²\\boldsymbol{y}, observed nn times sample, can written l=P(ğ²)n=(âˆ‘k=1KP(xk)P(ğ²|xk))n, \\begin{aligned} l &= P(\\boldsymbol{y})^n \\\\ &= \\Bigg (\\sum_{k=1}^K P(x_k)P(\\boldsymbol{y}|x_k)\\Bigg)^n, \\end{aligned} Assuming local independence, can rewrite conditional probabilities P(ğ²|xk)=âˆj=1JP(yj|xk), P(\\boldsymbol{y}|x_k) = \\prod_{j=1}^J P(y_j|x_k), yjy_j denotes score item jj. assumption, likelihood can rewritten l=(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))n,l = \\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg)^n, logarithm likelihood becomes ll=nlog(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)).ll = n \\log\\Bigg(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Bigg).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"first-order-derivatives","dir":"Articles","previous_headings":"","what":"First-order derivatives","title":"The Latent Class model","text":"partial derivative llll respect probability belonging class kk âˆ‚llâˆ‚P(xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆj=1JP(yj|xg). \\frac{\\partial ll}{\\partial P(x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} \\prod_{j=1}^J P(y_j|x_g). hand, partial derivative llll respect probability scoring particular yjy_j belonging class kk âˆ‚llâˆ‚P(ym|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial ll}{\\partial P(y_m|x_g)} = \\frac{n}{\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"second-order-derivatives","dir":"Articles","previous_headings":"","what":"Second-order derivatives","title":"The Latent Class model","text":"second partial derivative llll respect probability belonging class kk âˆ‚2llâˆ‚P(xg)âˆ‚P(xh)=âˆ’nâˆj=1JP(yj|xh)âˆj=1JP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2 \\frac{\\partial^2 ll}{\\partial P(x_g) \\partial P(x_h)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) \\prod_{j=1}^J P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2} âˆ‚llâˆ‚P(ym|xg)P(ym|xg)=âˆ’nP(xg)âˆjâ‰ mP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_m|x_g)} = -\\frac{n P(x_g)\\prod_{j \\neq m} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(ym|xg)P(yn|xg)=nâˆ‘k=1KP(xk)âˆj=1JP(yj|xk)P(xg)âˆjâ‰ m,nP(yj|xg)âˆ’nP(xg)âˆjâ‰ nP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_g)} = \\frac{n \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) P(x_g) \\prod_{j\\neq m,n} P(y_j|x_g) - n P(x_g)\\prod_{j \\neq n} P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll respect probability scoring particular ymy_m yny_n belonging class gg hh âˆ‚llâˆ‚P(ym|xg)P(yn|xh)=âˆ’nP(xh)âˆjâ‰ nP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(y_m|x_g) P(y_n|x_h)} = -\\frac{n P(x_h) \\prod_{j\\neq n} P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. second partial derivative llll probability belonging class gg probability scoring particular ymy_m belonging class hh âˆ‚llâˆ‚P(xg)âˆ‚P(ym|xg)=nâˆjâ‰ mP(yj|xg)âˆ‘k=1KP(xk)âˆj=1JP(yj|xk)âˆ’nâˆj=1JP(yj|xg)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_g) \\partial P(y_m|x_g)} = \\frac{n \\prod_{j\\neq m} P(y_j|x_g) \\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k) - n \\prod_{j=1}^J P(y_j|x_g) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}. âˆ‚llâˆ‚P(xh)âˆ‚P(ym|xg)=âˆ’nâˆj=1JP(yj|xh)P(xg)âˆjâ‰ mP(yj|xg)(âˆ‘k=1KP(xk)âˆj=1JP(yj|xk))2. \\frac{\\partial ll}{\\partial P(x_h) \\partial P(y_m|x_g)} = -\\frac{n \\prod_{j=1}^J P(y_j|x_h) P(x_g) \\prod_{j\\neq m} P(y_j|x_g)}{\\Big(\\sum_{k=1}^K P(x_k)\\prod_{j=1}^J P(y_j|x_k)\\Big)^2}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"model-for-the-conditional-probabilities","dir":"Articles","previous_headings":"","what":"Model for the conditional probabilities","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}. âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"bernoulli","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Bernoulli","title":"The Latent Class model","text":"yjy_j bernoulli random variable, conditional probability becomes P(yj|xk)=Î¸jyj(1âˆ’Î¸j)1âˆ’yj, P(y_j|x_k) = \\theta_j^{y_j} (1-\\theta_j)^{1-y_j},  Î¸j\\theta_j probability endorsing item jj (.e., yj=1y_j=1). partial derivative respect Î¸j\\theta_j âˆ‚P(yj|xk)Î¸j=12yjâˆ’1. \\frac{\\partial P(y_j|x_k)}{\\theta_j} = \\frac{1}{2y_j - 1}.","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"multinomial","dir":"Articles","previous_headings":"Latent Class Analysis","what":"Multinomial","title":"The Latent Class model","text":"âˆ‚P(ym|xg)âˆ‚Î¸mk|g=nlP(xg)âˆjâ‰ mP(yj|xg). \\frac{\\partial P(y_m|x_g)}{\\partial \\theta_{m_k|g}} = \\frac{n}{l} P(x_g)\\prod_{j\\neq m} P(y_j|x_g).","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"link-function","dir":"Articles","previous_headings":"","what":"Link function","title":"The Latent Class model","text":"softmax","code":""},{"path":"https://marcosjnez.github.io/latent/articles/lca_tutorial.html","id":"evaluating-the-likelihood","dir":"Articles","previous_headings":"","what":"Evaluating the likelihood","title":"The Latent Class model","text":"trick prevent undeflow","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcos JimÃ©nez. Maintainer. Mauricio Garnier-Villarreal. . Vithor R. Franco. .","code":""},{"path":"https://marcosjnez.github.io/latent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"JimÃ©nez M, Garnier-Villarreal M, Franco VR (2025). latent: R package Latent Variable Modeling. R package version 0.1.0, https://github.com/Marcosjnez/latent.","code":"@Manual{,   title = {latent: An R package for Latent Variable Modeling},   author = {Marcos JimÃ©nez and Mauricio Garnier-Villarreal and Vithor R. Franco},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/Marcosjnez/latent}, }"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"latent-latent-class-and-factor-analysis-models","dir":"","previous_headings":"","what":"An R package for Latent Class and Factor Analysis Models","title":"An R package for Latent Class and Factor Analysis Models","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-windows-and-linux","dir":"","previous_headings":"","what":"Installation in Windows and Linux","title":"An R package for Latent Class and Factor Analysis Models","text":"","code":"devtools::install_github(\"marcosjnez/latent\", force = TRUE)"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"installation-in-macos","dir":"","previous_headings":"","what":"Installation in macOS","title":"An R package for Latent Class and Factor Analysis Models","text":"Install macrtools R package James Balamuta: Install Command Line Tools R Compilation Toolchain (take minutes): Get OpenMP support: difficulties installation, check following resources: https://mac.thecoatlessprofessor.com/macrtools/index.html https://mac.thecoatlessprofessor.com/macrtools/reference/openmp.html Finally,","code":"# install.packages(\"remotes\") remotes::install_github(\"coatless-mac/macrtools\") macrtools::macos_rtools_install() macrtools::openmp_install() devtools::install_github(\"marcosjnez/latent\", force = TRUE)"},{"path":"https://marcosjnez.github.io/latent/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"An R package for Latent Class and Factor Analysis Models","text":"package development supported â€œDYNANSE: Righting Wrongs. Life Course Dynamics Approach Non-Standard Employmentâ€ project, received funding European Research Council (ERC) European Unionâ€™s Horizon 2020 research innovation programme (grant agreement 864471).","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"dataset lavaan R package.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"","code":"HolzingerSwineford1939"},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"data frame 301 rows 15 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/HolzingerSwineford1939.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: HolzingerSwineford1939 â€” HolzingerSwineford1939","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: cancer â€” cancer","title":"Example dataset: cancer â€” cancer","text":"dataset 475 rows 13 columns.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: cancer â€” cancer","text":"","code":"cancer"},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: cancer â€” cancer","text":"data frame 475 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cancer.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: cancer â€” cancer","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"Wrapper lcfa function fit Confirmatory Factor Analysis (CFA) model lavaan syntax.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"","code":"lcfa(data, model = NULL, cor = \"pearson\", estimator = \"ml\", group = NULL, sample.cov = NULL, nobs = NULL, W = NULL, positive = FALSE, penalties = TRUE, missing = \"pairwise.complete.obs\", std.lv = FALSE, do.fit = TRUE, control = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"data data frame matrix. model lavaan's model syntax. cor Correlation types: \"pearson\" \"poly\". Defaults \"pearson\". estimator Available estimators: \"ml\", \"uls\", \"dwls\". Defaults \"ml\". group . sample.cov Covariance matrix items. Defaults NULL. nobs Number observations. Defaults NULL. W Custom weight matrix \"dwls\". Defaults NULL. positive Force least positive-semidefinite solutions. Defaults FALSE penalties list penalty terms parameters. missing Method handle missing data. std.lv Provide parameters standardized model. .fit TRUE fit model FALSE return model setup. Defaults TRUE. control List control parameters optimization algorithm. See 'details' information.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"List following objects: version Version number 'latent' model estimated. call Code used estimate model. ModelInfo Model information. Optim Output optimizer. parameters Structure model parameters. transparameters Structure transformed model parameters. loglik Logarithm likelihood model. penalized_loglik Logarithm likelihood + logarithm priors model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"cfast estimates confirmatory factor models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/cfast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper to the lcfa function to fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” cfast","text":"","code":"if (FALSE) { # \\dontrun{ # The famous Holzinger and Swineford (1939) example HS.model <- ' visual  =~ x1 + x2 + x3               textual =~ x4 + x5 + x6               speed   =~ x7 + x8 + x9 '  fit <- lcfa(model = HS.model, data = HolzingerSwineford1939) summary(fit, digits = 3L) } # }"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: empathy â€” empathy","title":"Example dataset: empathy â€” empathy","text":"dataset tidySEM R package 467 rows 13 columns. first 6 columns continuous item responses.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: empathy â€” empathy","text":"","code":"empathy"},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: empathy â€” empathy","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/empathy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: empathy â€” empathy","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted values for Latent Class Analysis. â€” fitted.llca","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"Get fitted class membership probabilities latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"","code":"fitted(model)"},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"model Fitted llca object.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"Stuff: dof Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/fitted.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitted values for Latent Class Analysis. â€” fitted.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” getfit.lcfa","title":"Fit indices â€” getfit.lcfa","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” getfit.lcfa","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” getfit.lcfa","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” getfit.lcfa","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” getfit.lcfa","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” getfit.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” getfit.llca","title":"Fit indices â€” getfit.llca","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” getfit.llca","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” getfit.llca","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” getfit.llca","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” getfit.llca","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/getfit.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” getfit.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: gss82 â€” gss82","title":"Example dataset: gss82 â€” gss82","text":"dataset poLCA R package 1202 rows 4 columns. Items dichotomous polytomous.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: gss82 â€” gss82","text":"","code":"gss82"},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: gss82 â€” gss82","text":"data frame 1202 rows 4 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/gss82.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: gss82 â€” gss82","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/hexaco.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: hexaco â€” hexaco","title":"Example dataset: hexaco â€” hexaco","text":"dataset https://osf.io/72zp3/.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/hexaco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: hexaco â€” hexaco","text":"","code":"hexaco"},{"path":"https://marcosjnez.github.io/latent/reference/hexaco.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: hexaco â€” hexaco","text":"data frame 5 different samples (28143 rows) 100 HEXACO items: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/hexaco.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: hexaco â€” hexaco","text":"Generated example","code":""},{"path":"https://marcosjnez.github.io/latent/reference/hexaco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example dataset: hexaco â€” hexaco","text":"","code":"if (FALSE) { # \\dontrun{ # Check samples and sample sizes samples <- unique(hexaco$sample) # industry mooc fire student dutch Ns <- sapply(samples, FUN = function(x) sum(hexaco$sample == x)) names(Ns) <- samples  # Subset the items pertaining to the HEXACO-100 selection <- 5:104 full <- hexaco[, selection]  mooc <- full[hexaco$sample == samples[2], ] dim(mooc)  model.EM <- \"FEA ~= hexemfea146 + hexemfea170 + hexemfea74 + hexemfea2              ANX ~= hexemanx128 + hexemanx8 + hexemanx80 + hexemanx176              DEP ~= hexemdep62 + hexemdep182 + hexemdep134 + hexemdep158              SEN ~= hexemsen44 + hexemsen164 + hexemsen20 + hexemsen68\"  fit <- lcfa(model = model.EM, data = mooc,             ordered = TRUE, estimator = \"ml\", do.fit = TRUE,             control = NULL) fit@loglik # -0.283407 fit@penalized_loglik # -0.283407 fit@loss # 0.1574787 fit@Optim$opt$iterations fit@Optim$opt$convergence fit@timing } # }"},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors â€” latInspect.lcfa","title":"Standard Errors â€” latInspect.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors â€” latInspect.lcfa","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors â€” latInspect.lcfa","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors â€” latInspect.lcfa","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors â€” latInspect.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors â€” latInspect.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspect objects from fitted lca models. â€” latInspect.llca","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"Inspect objects.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"","code":"latInspect(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"fit model fitted lca. digits Number digits print.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"List one following objects: class . posterior . profile .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"Extract objects fitted lca object.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latInspect.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inspect objects from fitted lca models. â€” latInspect.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":null,"dir":"Reference","previous_headings":"","what":"An R package for Latent Variable Modeling â€” latent-package","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Fit measurement models discrete continuous latent variables.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An R package for Latent Variable Modeling â€” latent-package","text":"DESCRIPTION file: package yet installed build time.   Index:  package yet installed build time.  ~~ overview use package, including important functions ~~","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An R package for Latent Variable Modeling â€” latent-package","text":"Marcos JimÃ©nez [fnd, cre],   Mauricio Garnier-Villarreal [cre],   Vithor R. Franco [cre] Maintainer: Marcos JimÃ©nez <m.j.jimenezhenriquez@vu.nl>, Mauricio Garnier-Villarreal <m.garniervillarreal@vu.nl>, Vithor R. Franco <vithorfranco@gmail.com>","code":""},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An R package for Latent Variable Modeling â€” latent-package","text":"~~ Literature references background information ~~","code":""},{"path":[]},{"path":"https://marcosjnez.github.io/latent/reference/latent-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An R package for Latent Variable Modeling â€” latent-package","text":"","code":"# simple examples of the most important functions"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Analysis. â€” lca","title":"Latent Class Analysis. â€” lca","text":"Estimate latent class models gaussian multinomial item models, without covariates predict class membership.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Analysis. â€” lca","text":"","code":"lca(data, nclasses = 2L, item = rep(\"gaussian\", ncol(data)),     X = NULL, penalties = TRUE, model = NULL, mimic = \"LG\",     start = NULL, do.fit = TRUE, verbose = TRUE, control = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Analysis. â€” lca","text":"data data frame matrix. nclasses Number latent classes. item Character vector model item (.e., \"gaussian\" \"multinomial\"). Defaults \"gaussian\" items. X Matrix covariates. penalties Boolean list penalty terms parameters. model List parameter labels. See 'details' information. mimic String. Replicate output softwares. Use \"LG\" replicate output LatentGOLD. start List starting values parameters. See 'details' information. .fit TRUE fit model FALSE return model setup. Defaults TRUE. control List control parameters optimization algorithm. See 'details' information. verbose Print information model estimation. Defaults FALSE.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Analysis. â€” lca","text":"List following objects: version Version number 'latent' model estimated. call Code used estimate model. ModelInfo Model information. Optim Output optimizer. user_model Structure relevant parameters. parameters Structure model parameters. transparameters Structure transformed model parameters. posterior Posterior probability class membership. state Class highest posterior probability. loglik Logarithm likelihood model. penalized_loglik Logarithm likelihood + logarithm priors model. loglik_case Logarithm likelihood pattern. summary_table Table summaries fitted model. Useful items 'multinomial'. ClassConditional Parameters conditional class memberships. ResponseConditional Probability class memberships conditional item response. available items 'multinomial' likelihood. probCat Marginal probability item response. available items 'multinomial' likelihood.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Analysis. â€” lca","text":"lca estimates models categorical continuous data.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Analysis. â€” lca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent Class Analysis. â€” lca","text":"","code":"if (FALSE) { # \\dontrun{  fit <- lca(data = gss82, nclasses = 3L,            item = rep(\"multinomial\", ncol(gss82)),            penalties = TRUE, do.fit = TRUE) fit@timing fit@loglik # -2754.643 fit@penalized_loglik # -2759.507 fit@Optim$opt$iterations  # Plot model fit info: fit  # Get fit indices: getfit(fit)  # Get a summary: summary(fit)  # Inspect model objects: latInspect(fit, what = \"coefs\", digits = 3) latInspect(fit, what = \"classes\", digits = 3) latInspect(fit, what = \"profile\", digits = 3) latInspect(fit, what = \"posterior\", digits = 3) latInspect(fit, what = \"table\", digits = 3) latInspect(fit, what = \"pattern\", digits = 3)  # Get standard errors: SE <- se(fit, type = \"standard\", model = \"user\", digits = 4) SE$table  # Get confidence intervals: CI <- ci(fit, type = \"standard\", model = \"user\",         confidence = 0.95, digits = 2) CI$table } # }"},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"Fit Confirmatory Factor Analysis (CFA) model lavaan syntax.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"","code":"lcfa(data, model = NULL, estimator = \"ml\", ordered = FALSE, group = NULL, sample.cov = NULL, nobs = NULL, positive = FALSE, penalties = TRUE, missing = \"pairwise.complete.obs\", std.lv = FALSE, do.fit = TRUE, mimic = 'latent', control = NULL, ...)"},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"data data frame matrix. model lavaan's model syntax. estimator Available estimators: \"ml\", \"uls\", \"dwls\". Defaults \"ml\". ordered Logical. Defaults TRUE. group String. Name variable splits data different groups. sample.cov Covariance matrix items. Defaults NULL. nobs Number observations. Defaults NULL. positive Force positive-definite solution. Defaults FALSE. penalties list penalty terms parameters. missing Method handle missing data. std.lv Provide parameters standardized model. .fit TRUE fit model FALSE return model setup. Defaults TRUE. mimic String. Choose output want obtain. Defaults 'latent'. control List control parameters optimization algorithm. See 'details' information. ... Additional lavaan arguments. See ?lavaan information.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"List following objects: version Version number 'latent' model estimated. call Code used estimate model. ModelInfo Model information. Optim Output optimizer. parameters Structure model parameters. transparameters Structure transformed model parameters. loglik Logarithm likelihood model. penalized_loglik Logarithm likelihood + logarithm priors model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"lcfa estimates confirmatory factor models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lcfa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Confirmatory Factor Analysis (CFA) model with lavaan syntax. â€” lcfa","text":"","code":"if (FALSE) { # \\dontrun{ # The famous Holzinger and Swineford (1939) example HS.model <- ' visual  =~ x1 + x2 + x3               textual =~ x4 + x5 + x6               speed   =~ x7 + x8 + x9 '  fit <- lcfa(model = HS.model, data = HolzingerSwineford1939) summary(fit, digits = 3L) } # }"},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"Maximum likelihood estimation positive definite polychoric correlation matrices.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"","code":"lpoly(data = NULL, penalties = TRUE, do.fit = TRUE, control = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"data data frame matrix raw data. penalties Force positive-definite solution. Defaults TRUE. .fit TRUE fit model FALSE return model setup. Defaults TRUE. control List control parameters optimization algorithm. See 'details' information.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"List following objects: version Version number 'latent' model estimated. call Code used estimate model. ModelInfo Model information. Optim Output optimizer. parameters Structure model parameters. transparameters Structure transformed model parameters. loglik Logarithm likelihood model. penalized_loglik Logarithm likelihood + logarithm priors model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"lpoly estimates positive-definite polychoric correlation matrices.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/lpoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum likelihood estimation of positive definite polychoric correlation matrices. â€” lpoly","text":"","code":"if (FALSE) { # \\dontrun{ fit <- lpoly(data = values) } # }"},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicted values for Latent Class Analysis. â€” predict.llca","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"Get predicted class membership probabilities latent class models.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"","code":"predict(model, new = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"model Fitted llca object. new Matrix data.frame new predictors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"Stuff: dof Degrees freedom","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"None.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/predict.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predicted values for Latent Class Analysis. â€” predict.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors â€” se.lcfa","title":"Standard Errors â€” se.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors â€” se.lcfa","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors â€” se.lcfa","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors â€” se.lcfa","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors â€” se.lcfa","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors â€” se.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Errors â€” se.llca","title":"Standard Errors â€” se.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Errors â€” se.llca","text":"","code":"se(fit)"},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Errors â€” se.llca","text":"fit model fitted lca. confidence Coverage confidence interval.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Errors â€” se.llca","text":"List following objects: vcov Variance-covariance matrix parameters. se Standard errors. SE Standard errors model list.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Errors â€” se.llca","text":"Compute standard errors.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/se.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Errors â€” se.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate factor structures with misspecification errors. â€” simfactor","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"Simulate factor bifactor structures crossloadings, correlated factors, .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"","code":"simfactor(nfactors = 5, nitems = 6, loadings = \"medium\", crossloadings = 0, correlations = 0, estimator = \"minres\", fit = \"rmsr\", misfit = 0, error_method = \"cudeck\", efa = FALSE, ngenerals = 0, loadings_g = \"medium\", correlations_g = 0, pure = FALSE, lambda = NULL, Phi = NULL, Psi = NULL)"},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"nfactors Number factors. nitems Number items per factor. loadings Loadings' magnitude factors: \"low\", \"medium\" \"high\". Defaults \"medium\". crossloadings Magnitude cross-loadings among group factors. Defaults 0. correlations_g Correlation among general factors. Defaults 0. correlations Correlation among factors. Defaults 0. estimator estimator used generate population error: \"minres\" \"ml\". fit Fit index control population error. misfit Misfit value generate population error. error_method Method used control population error: c(\"yuan\", \"cudeck\"). Defaults \"cudeck\". efa Reproduce error EFA CFA. Defaults FALSE (CFA). ngenerals Number general factors. loadings_g Loadings' magnitude general factors: \"low\", \"medium\" \"high\". Defaults \"medium\". pure Fix pure item general factor. Defaults FALSE. lambda Custom loading matrix. Phi NULL, factors correlated value given correlations. Phi Custom Phi matrix. lambda NULL, Phi conformable loading matrix specified arguments. Psi Custom Psi matrix.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"List following objects: lambda Population loading matrix. Phi Population factor correlation matrix. Psi Population covariance matrix errors. R Model correlation matrix. R_error Model correlation matrix misspecification errors. uniquenesses Population uniquenesses. delta Minimum loss function correspond misfit value.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"simfactor generates bi-factor generalized bifactor patterns cross-loadings, pure items correlations among general group factors. crossloading different 0, one cross-loading introduced item pertaining group factor. pure TRUE, one item loading group factor removed item loads entirely general factor. maintain item communalities constant upon modifications, item loading factors may shrunk (adding cross-loadings) increase (setting pure items). Loading magnitudes may range 0.3-0.5 (\"low\"), 0.4-0.6 (\"medium\") 0.5-0.7 (\"high\"). Custom ranges can supplied vectors (.e., c(0.2, 0.5))","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"Cudeck, R., & Browne, M. W. (1992). Constructing covariance matrix yields specified minimizer specified minimum discrepancy function value. Psychometrika, 57(3), 357â€“369. doi:10.1007/BF02295424 JimÃ©nez, M., Abad, F. J., Garcia-Garzon, E., & Garrido, L. E. (2023). Exploratory Bi-factor Analysis Multiple General Factors. Multivariate Behavioral Research, 58(6), 1072â€“1089. doi:10.1080/00273171.2023.2189571 JimÃ©nez, M., Abad, F. J., Garcia-Garzon, E., Golino, H., Christensen, . P., & Garrido, L. E. (2023). Dimensionality assessment bifactor structures multiple general factors: network psychometrics approach. Psychological Methods. Advance online publication. doi:10.1037/met0000590 Yuan, K.-H., & Hayashi, K. (2003). Bootstrap approach inference power analysis based three test statistics covariance structure models. British Journal Mathematical Statistical Psychology, 56(1), 93â€“110. doi:10.1348/000711003321645368","code":""},{"path":"https://marcosjnez.github.io/latent/reference/simfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate factor structures with misspecification errors. â€” simfactor","text":"","code":"# Simulate data: sim <- simfactor(nfactors = 3, nitems = 4, correlations = 0.40,                  crossloadings = 0.30) sim$lambda #>               S1        S2        S3 #> item1  0.4804656 0.0000000 0.3000000 #> item2  0.4391340 0.0000000 0.0000000 #> item3  0.4807076 0.0000000 0.0000000 #> item4  0.4127323 0.0000000 0.0000000 #> item5  0.3000000 0.4777403 0.0000000 #> item6  0.0000000 0.5951096 0.0000000 #> item7  0.0000000 0.4579785 0.0000000 #> item8  0.0000000 0.5356761 0.0000000 #> item9  0.0000000 0.3000000 0.5470639 #> item10 0.0000000 0.0000000 0.4391913 #> item11 0.0000000 0.0000000 0.5961079 #> item12 0.0000000 0.0000000 0.5483043 sim$Phi #>      [,1] [,2] [,3] #> [1,]  1.0  0.4  0.4 #> [2,]  0.4  1.0  0.4 #> [3,]  0.4  0.4  1.0 scores <- MASS::mvrnorm(1e3, rep(0, nrow(sim$R_error)), Sigma = sim$R_error) s <- cor(scores)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” summary.lcfa","title":"Fit indices â€” summary.lcfa","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” summary.lcfa","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” summary.lcfa","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” summary.lcfa","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” summary.lcfa","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.lcfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” summary.lcfa","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit indices â€” summary.llca","title":"Fit indices â€” summary.llca","text":"Compute fit indices model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit indices â€” summary.llca","text":"","code":"getfit(model)"},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit indices â€” summary.llca","text":"model data.frame matrix response.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit indices â€” summary.llca","text":"List following fit indices: AIC . BIC .","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit indices â€” summary.llca","text":"getfit computes fit indices related specific model.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/summary.llca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit indices â€” summary.llca","text":"None yet.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset: values â€” values","title":"Example dataset: values â€” values","text":"dataset poLCA R package 216 rows 4 columns. 4 columns dichotomous items.","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset: values â€” values","text":"","code":"values"},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset: values â€” values","text":"data frame 467 rows 13 variables: x integer 1 5 y lowercase letter","code":""},{"path":"https://marcosjnez.github.io/latent/reference/values.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset: values â€” values","text":"Generated example","code":""}]
